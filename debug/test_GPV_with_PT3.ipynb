{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from network.gap_layers import *\n",
    "from datasets.datasets_pair import *\n",
    "import functools\n",
    "from network.sym_v1 import *\n",
    "from loss.utils import *\n",
    "from network.utils import *\n",
    "from network.PointTransformerv3 import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import spconv.pytorch as spconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_PT3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pt3 = PointTransformerV3()\n",
    "        self.rot_green_head = nn.Linear(64, 3)\n",
    "        self.rot_red_head = nn.Linear(64, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, pc_pairs: List[PointCloudPair]):\n",
    "        pc1s = [pc_pair.pc1 for pc_pair in pc_pairs]\n",
    "        pc2s = [pc_pair.pc2 for pc_pair in pc_pairs]\n",
    "        bs = len(pc_pairs)\n",
    "        pc_batch_1: PointCloudBatch = PointCloud.collate(pc1s)\n",
    "        pc_batch_2: PointCloudBatch = PointCloud.collate(pc2s)\n",
    "        \n",
    "        pc_voxel_id_1 = pc_batch_1.pc_voxel_id\n",
    "        pc_voxel_id_2 = pc_batch_2.pc_voxel_id\n",
    "        in_dict_1 = {\n",
    "            \"feat\": pc_batch_1.voxel_tensor.features,\n",
    "            \"grid_coord\": pc_batch_1.voxel_tensor.indices[:, 1:],\n",
    "            \"batch\": pc_batch_1.voxel_tensor.indices[:, 0],\n",
    "            \"coord\": pc_batch_1.voxel_tensor.indices[:, 1:] * 0.01,\n",
    "            \"grid_size\": 0.01\n",
    "        }\n",
    "        in_dict_2 = {\n",
    "            \"feat\": pc_batch_2.voxel_tensor.features,\n",
    "            \"grid_coord\": pc_batch_2.voxel_tensor.indices[:, 1:],\n",
    "            \"batch\": pc_batch_2.voxel_tensor.indices[:, 0],\n",
    "            \"coord\": pc_batch_2.voxel_tensor.indices[:, 1:] * 0.01,\n",
    "            \"grid_size\": 0.01\n",
    "        }\n",
    "        outs_1 = self.pt3(in_dict_1)\n",
    "        outs_2 = self.pt3(in_dict_2)\n",
    "        pc_feature_1 = outs_1['feat'][pc_voxel_id_1]\n",
    "        pc_feature_2 = outs_2['feat'][pc_voxel_id_2]\n",
    "\n",
    "        pc_feature_1 = pc_feature_1.view(bs, -1, 64) # bs,n,64\n",
    "        pc_feature_2 = pc_feature_2.view(bs, -1, 64)\n",
    "\n",
    "        rot_green_1 = self.rot_green_head(pc_feature_1).mean(dim=1).view(bs, 3) # bs,n,3\n",
    "        rot_green_2 = self.rot_green_head(pc_feature_2).mean(dim=1).view(bs, 3)\n",
    "\n",
    "        rot_red_1 = self.rot_red_head(pc_feature_1).mean(dim=1).view(bs, 3)\n",
    "        rot_red_2 = self.rot_red_head(pc_feature_2).mean(dim=1).view(bs, 3) # bs,3\n",
    "        \n",
    "        return (rot_green_1, rot_green_2), (rot_red_1, rot_red_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "class fs_net_loss_R(nn.Module):\n",
    "    def __init__(self, loss_type=\"smoothl1\"):\n",
    "        super(fs_net_loss_R, self).__init__()\n",
    "        if loss_type == 'l1':\n",
    "            self.loss_func_t = nn.L1Loss()\n",
    "            self.loss_func_s = nn.L1Loss()\n",
    "            self.loss_func_Rot1 = nn.L1Loss()\n",
    "            self.loss_func_Rot2 = nn.L1Loss()\n",
    "            self.loss_func_r_con = nn.L1Loss()\n",
    "            self.loss_func_Recon = nn.L1Loss()\n",
    "        elif loss_type == 'smoothl1':   # same as MSE\n",
    "            self.loss_func_t = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_s = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Rot1 = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Rot2 = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_r_con = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Recon = nn.SmoothL1Loss(beta=0.3)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, pred_list, gt_list, sym):\n",
    "        loss_list = {}\n",
    "\n",
    "        self.rot_1_w = 1\n",
    "\n",
    "        loss_list[\"Rot1\"] = self.rot_1_w * self.cal_loss_Rot1(pred_list[\"Rot1\"], gt_list[\"Rot1\"])\n",
    "\n",
    "        loss_list[\"Rot2\"] = self.rot_1_w * self.cal_loss_Rot2(pred_list[\"Rot2\"], gt_list[\"Rot2\"], sym)\n",
    "\n",
    "        # loss_list[\"Recon\"] = self.recon_w * self.cal_loss_Recon(pred_list[\"Recon\"], gt_list[\"Recon\"])\n",
    "\n",
    "        # loss_list[\"Tran\"] = self.tran_w * self.cal_loss_Tran(pred_list[\"Tran\"], gt_list[\"Tran\"])\n",
    "    \n",
    "        # loss_list[\"Size\"] = self.size_w * self.cal_loss_Size(pred_list[\"Size\"], gt_list[\"Size\"])\n",
    "\n",
    "        return loss_list\n",
    "\n",
    "    def cal_loss_Rot1(self, pred_v, gt_v):\n",
    "        bs = pred_v.shape[0]\n",
    "        res = torch.zeros([bs], dtype=torch.float32, device=pred_v.device)\n",
    "        for i in range(bs):\n",
    "            pred_v_now = pred_v[i, ...]\n",
    "            gt_v_now = gt_v[i, ...]\n",
    "            res[i] = self.loss_func_Rot1(pred_v_now, gt_v_now)\n",
    "        res = torch.mean(res)\n",
    "        return res\n",
    "\n",
    "    def cal_loss_Rot2(self, pred_v, gt_v, sym):\n",
    "        bs = pred_v.shape[0]\n",
    "        res = 0.0\n",
    "        valid = 0.0\n",
    "        for i in range(bs):\n",
    "            sym_now = sym[i, 0]\n",
    "            if sym_now == 1:\n",
    "                continue\n",
    "            else:\n",
    "                pred_v_now = pred_v[i, ...]\n",
    "                gt_v_now = gt_v[i, ...]\n",
    "                res += self.loss_func_Rot2(pred_v_now, gt_v_now)\n",
    "                valid += 1.0\n",
    "        if valid > 0.0:\n",
    "            res = res / valid\n",
    "        return res\n",
    "\n",
    "    def cal_loss_Recon(self, pred_recon, gt_recon):\n",
    "        return self.loss_func_Recon(pred_recon, gt_recon)\n",
    "\n",
    "    def cal_loss_Tran(self, pred_trans, gt_trans):\n",
    "        return self.loss_func_t(pred_trans, gt_trans)\n",
    "\n",
    "    def cal_loss_Size(self, pred_size, gt_size):\n",
    "        return self.loss_func_s(pred_size, gt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/16T/zhangran/GAPartNet_re_rendered/train\"\n",
    "test_intra_dir = \"/16T/zhangran/GAPartNet_re_rendered/test_intra\"\n",
    "test_inter_dir = \"/16T/zhangran/GAPartNet_re_rendered/test_inter\"\n",
    "def get_datasets(root_dir, test_intra_dir, test_inter_dir, voxelization=False, shot=False):\n",
    "    if shot:\n",
    "        few_shot = True\n",
    "        few_shot_num = 20\n",
    "    else:\n",
    "        few_shot = False\n",
    "        few_shot_num = None\n",
    "\n",
    "    dataset_train = GAPartNetPair(\n",
    "        Path(root_dir) / \"pth\",\n",
    "        Path(root_dir) / \"meta\",\n",
    "        shuffle=True,\n",
    "        max_points=2000,\n",
    "        augmentation=True,\n",
    "        voxelization=voxelization, \n",
    "        group_size=2,\n",
    "        voxel_size=[0.01,0.01,0.01],\n",
    "        few_shot=few_shot,\n",
    "        few_shot_num=few_shot_num,\n",
    "        pos_jitter=0.1,\n",
    "        with_pose=True,\n",
    "        color_jitter=0.3,\n",
    "        flip_prob=0.3,\n",
    "        rotate_prob=0.3,\n",
    "    )\n",
    "\n",
    "    dataset_test_intra = GAPartNetPair(\n",
    "        Path(test_intra_dir) / \"pth\",\n",
    "        Path(test_intra_dir) / \"meta\",\n",
    "        shuffle=False,\n",
    "        max_points=2000,\n",
    "        augmentation=True,\n",
    "        voxelization=voxelization, \n",
    "        group_size=2,\n",
    "        voxel_size=[0.01,0.01,0.01],\n",
    "        few_shot=few_shot,\n",
    "        few_shot_num=few_shot_num,\n",
    "        pos_jitter=0.1,\n",
    "        with_pose=True,\n",
    "        color_jitter=0.3,\n",
    "        flip_prob=0.3,\n",
    "        rotate_prob=0.3,\n",
    "    )\n",
    "\n",
    "    dataset_test_inter = GAPartNetPair(\n",
    "        Path(test_inter_dir) / \"pth\",\n",
    "        Path(test_inter_dir) / \"meta\",\n",
    "        shuffle=False,\n",
    "        max_points=2000,\n",
    "        augmentation=True,\n",
    "        voxelization=voxelization, \n",
    "        group_size=2,\n",
    "        voxel_size=[0.01,0.01,0.01],\n",
    "        few_shot=few_shot,\n",
    "        few_shot_num=few_shot_num,\n",
    "        pos_jitter=0.1,\n",
    "        with_pose=True,\n",
    "        color_jitter=0.3,\n",
    "        flip_prob=0.3,\n",
    "        rotate_prob=0.3,\n",
    "    )\n",
    "\n",
    "    return dataset_train, dataset_test_intra, dataset_test_inter\n",
    "\n",
    "def get_dataloaders(dataset_train, dataset_test_intra, dataset_test_inter, batch_size=16, num_workers=8):\n",
    "    dataloader_train = DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=data_utils.trivial_batch_collator,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    # test_intra_sampler = DistributedSampler(dataset_test_intra, shuffle=False)\n",
    "    dataloader_test_intra = DataLoader(\n",
    "        dataset_test_intra,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=data_utils.trivial_batch_collator,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        # sampler=test_intra_sampler\n",
    "    )\n",
    "    # test_inter_sampler = DistributedSampler(dataset_test_inter, shuffle=False)\n",
    "    dataloader_test_inter = DataLoader(\n",
    "        dataset_test_inter,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=data_utils.trivial_batch_collator,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        # sampler=test_inter_sampler\n",
    "    )\n",
    "    return dataloader_train, dataloader_test_intra, dataloader_test_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract ground truth rotation vectors from the batch of PointCloudPairs\n",
    "def ground_truth_rotations(rot_list: List[torch.Tensor]) -> np.ndarray:\n",
    "    rotations = []\n",
    "    for rot in rot_list:\n",
    "        # Assuming the rotations are stored as 3x3 matrices in pc_pair.rot_1 and pc_pair.rot_2\n",
    "        rotation_matrix = np.array(rot.cpu())  # Example using rot_1, adjust as needed\n",
    "        rotations.append(rotation_matrix)\n",
    "    return torch.tensor(np.stack(rotations))\n",
    "\n",
    "def train(model: nn.Module, \n",
    "          dataloader_train: DataLoader, \n",
    "          dataloader_test_inter: DataLoader, \n",
    "          dataloader_test_intra: DataLoader, \n",
    "          lr: int = 0.001, \n",
    "          num_epochs: int=100, \n",
    "          log_dir: str=None, \n",
    "          device: torch.device=None):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = fs_net_loss_R()\n",
    "    if not device:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    assert log_dir is not None, \"No Log Dir\"\n",
    "    log_dir = log_dir + \"/\" + str(datetime.today())\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    print(\"_________________________train_epoch___________________________\")\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        if epoch == 0:\n",
    "            # first test epoch\n",
    "            print(\"______________________first_test_epoch_________________________\")\n",
    "            torch.save(model.state_dict(), log_dir+r'/'+f\"GPV_[{epoch+1}|{num_epochs}].pth\")\n",
    "            test_metrics(model, dataloader_test_inter, device, writer, epoch, 'test_inter')\n",
    "            test_metrics(model, dataloader_test_intra, device, writer, epoch, 'test_intra')\n",
    "        for batch_idx, batch in enumerate(dataloader_train):\n",
    "            pc_pairs = [pair.to(device) for pair in batch]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            (p_green_R1, p_red_R1), (p_green_R2, p_red_R2) = model(pc_pairs)\n",
    "            \n",
    "            # Assuming we have ground truth rotations\n",
    "            R_green_gt1, R_red_gt1 = get_gt_v(ground_truth_rotations([pc.rot_1 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            R_green_gt2, R_red_gt2 = get_gt_v(ground_truth_rotations([pc.rot_2 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            \n",
    "            pred_list1 = {\n",
    "                \"Rot1\": p_green_R1,\n",
    "                \"Rot2\": p_red_R1,\n",
    "            }\n",
    "            gt_list1 = {\n",
    "                \"Rot1\": R_green_gt1.cuda(),\n",
    "                \"Rot2\": R_red_gt1.cuda(),\n",
    "            }\n",
    "            \n",
    "            pred_list2 = {\n",
    "                \"Rot1\": p_green_R2,\n",
    "                \"Rot2\": p_red_R2,\n",
    "            }\n",
    "            gt_list2 = {\n",
    "                \"Rot1\": R_green_gt2.cuda(),\n",
    "                \"Rot2\": R_red_gt2.cuda(),\n",
    "            }\n",
    "\n",
    "            sym1, sym2 = get_sym_from_input(pc_pairs)\n",
    "\n",
    "            loss_dict1 = criterion(pred_list1, gt_list1, sym1)\n",
    "            loss_dict2 = criterion(pred_list2, gt_list2, sym2)\n",
    "            loss = (loss_dict1['Rot1'] + loss_dict1['Rot2'] + loss_dict2['Rot1'] + loss_dict2['Rot2']) / 2.0\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # 每10个batch记录一次loss\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                writer.add_scalar('train/loss', loss.item(), global_step)\n",
    "                print(f\"Epoch:[{epoch + 1}|{num_epochs}],Batch:[{(batch_idx + 1)}|{len(dataloader_train)}],Loss:[{loss.item():.4f}]\")\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader_train)\n",
    "        print(f\"Epoch [{epoch+1}|{num_epochs}],Loss:{avg_loss:.4f}\")\n",
    "        writer.add_scalar('train/avg_loss', avg_loss, epoch)\n",
    "\n",
    "        # 每5个epoch跑一次测试集\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), log_dir+r'/'+f\"GPV_[{epoch+1}|{num_epochs}].pth\")\n",
    "            test_metrics(model, dataloader_test_inter, device, writer, epoch, 'test_inter')\n",
    "            test_metrics(model, dataloader_test_intra, device, writer, epoch, 'test_intra')\n",
    "\n",
    "\n",
    "def test_metrics(model, dataloader, device, writer, epoch, phase):\n",
    "    print(\"______________________\" + phase + \"_______________________\")\n",
    "    model.eval()\n",
    "    all_pred_rot_matrices = []\n",
    "    all_gt_rot_matrices = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            pc_pairs = [pair.to(device) for pair in batch]\n",
    "            (p_green_R1, p_red_R1), (p_green_R2, p_red_R2) = model(pc_pairs)\n",
    "            \n",
    "            # Assuming we have ground truth rotations\n",
    "            R_green_gt1, R_red_gt1 = get_gt_v(ground_truth_rotations([pc.rot_1 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            R_green_gt2, R_red_gt2 = get_gt_v(ground_truth_rotations([pc.rot_2 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            \n",
    "            # Convert predicted vectors and ground truth vectors back to rotation matrices\n",
    "            pred_rot_matrices1 = vectors_to_rotation_matrix(p_green_R1, p_red_R1)\n",
    "            pred_rot_matrices2 = vectors_to_rotation_matrix(p_green_R2, p_red_R2)\n",
    "            gt_rot_matrices1 = vectors_to_rotation_matrix(R_green_gt1, R_red_gt1)\n",
    "            gt_rot_matrices2 = vectors_to_rotation_matrix(R_green_gt2, R_red_gt2)\n",
    "            \n",
    "            # Store predictions and ground truths for metrics calculation\n",
    "            all_pred_rot_matrices.append(pred_rot_matrices1.cpu())\n",
    "            all_pred_rot_matrices.append(pred_rot_matrices2.cpu())\n",
    "            all_gt_rot_matrices.append(gt_rot_matrices1.cpu())\n",
    "            all_gt_rot_matrices.append(gt_rot_matrices2.cpu())\n",
    "    \n",
    "    all_pred_rot_matrices = torch.cat(all_pred_rot_matrices, dim=0)\n",
    "    all_gt_rot_matrices = torch.cat(all_gt_rot_matrices, dim=0)\n",
    "\n",
    "    mean_rot_error = calculate_pose_metrics(\n",
    "        all_pred_rot_matrices, all_gt_rot_matrices\n",
    "    )\n",
    "    writer.add_scalar(f'{phase}/mean_rot_error', mean_rot_error, epoch)\n",
    "    print(f\"{phase} - Epoch [{epoch+1}]: Mean Rotation Error: {mean_rot_error:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________train_epoch___________________________\n",
      "______________________first_test_epoch_________________________\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [1]: Mean Rotation Error: 92.3998\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [1]: Mean Rotation Error: 108.7847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1|40],Loss:1.2760\n",
      "Epoch [2|40],Loss:0.8810\n",
      "Epoch [3|40],Loss:0.5089\n",
      "Epoch [4|40],Loss:0.5419\n",
      "Epoch [5|40],Loss:0.4973\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [5]: Mean Rotation Error: 78.7313\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [5]: Mean Rotation Error: 77.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6|40],Loss:0.3958\n",
      "Epoch [7|40],Loss:0.4063\n",
      "Epoch [8|40],Loss:0.4237\n",
      "Epoch [9|40],Loss:0.3947\n",
      "Epoch [10|40],Loss:0.3484\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [10]: Mean Rotation Error: 83.9853\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [10]: Mean Rotation Error: 92.6282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11|40],Loss:0.3828\n",
      "Epoch [12|40],Loss:0.3744\n",
      "Epoch [13|40],Loss:0.3649\n",
      "Epoch [14|40],Loss:0.3721\n",
      "Epoch [15|40],Loss:0.3681\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [15]: Mean Rotation Error: 87.6344\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [15]: Mean Rotation Error: 90.3215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16|40],Loss:0.3425\n",
      "Epoch [17|40],Loss:0.3592\n",
      "Epoch [18|40],Loss:0.3289\n",
      "Epoch [19|40],Loss:0.3412\n",
      "Epoch [20|40],Loss:0.3220\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [20]: Mean Rotation Error: 81.4152\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [20]: Mean Rotation Error: 77.8457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21|40],Loss:0.3293\n",
      "Epoch [22|40],Loss:0.3207\n",
      "Epoch [23|40],Loss:0.3424\n",
      "Epoch [24|40],Loss:0.3217\n",
      "Epoch [25|40],Loss:0.3478\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [25]: Mean Rotation Error: 76.5967\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [25]: Mean Rotation Error: 77.4199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26|40],Loss:0.3191\n",
      "Epoch [27|40],Loss:0.3171\n",
      "Epoch [28|40],Loss:0.2993\n",
      "Epoch [29|40],Loss:0.3292\n",
      "Epoch [30|40],Loss:0.3127\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [30]: Mean Rotation Error: 76.9464\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [30]: Mean Rotation Error: 76.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31|40],Loss:0.3679\n",
      "Epoch [32|40],Loss:0.3690\n",
      "Epoch [33|40],Loss:0.3908\n",
      "Epoch [34|40],Loss:0.3692\n",
      "Epoch [35|40],Loss:0.3414\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [35]: Mean Rotation Error: 78.3154\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [35]: Mean Rotation Error: 76.3035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36|40],Loss:0.3542\n",
      "Epoch [37|40],Loss:0.3304\n",
      "Epoch [38|40],Loss:0.2493\n",
      "Epoch [39|40],Loss:0.3107\n",
      "Epoch [40|40],Loss:0.2589\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [40]: Mean Rotation Error: 68.2631\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [40]: Mean Rotation Error: 107.8630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = test_PT3()\n",
    "dataset_train, dataset_test_intra, dataset_test_inter = get_datasets(root_dir, test_intra_dir, test_inter_dir, voxelization=True, shot=True)\n",
    "dataloader_train, dataloader_test_intra, dataloader_test_inter = get_dataloaders(dataset_train, dataset_test_intra, dataset_test_inter)\n",
    "train(model, dataloader_train, dataloader_test_inter, dataloader_test_intra, 0.001, 40, \"./log_dir/PointTrnsformer_test_sym_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointTransformerV3().cuda()\n",
    "dataset_train, dataset_test_intra, dataset_test_inter = get_datasets(root_dir, test_intra_dir, test_inter_dir, voxelization=True, shot=True)\n",
    "dataloader_train, dataloader_test_intra, dataloader_test_inter = get_dataloaders(dataset_train, dataset_test_intra, dataset_test_inter)\n",
    "pairs = next(iter(dataloader_train))\n",
    "pc_pairs = [pair.to(\"cuda\") for pair in pairs]\n",
    "pc1s = [pc_pair.pc1 for pc_pair in pc_pairs]\n",
    "pc2s = [pc_pair.pc2 for pc_pair in pc_pairs]\n",
    "bs = len(pc_pairs)\n",
    "pc_batch_1: PointCloudBatch = PointCloud.collate(pc1s)\n",
    "# pc_batch_2: PointCloudBatch = PointCloud.collate(pc2s)\n",
    "# pc_batch_1.voxel_tensor.features\n",
    "in_dict_1 = {\n",
    "    \"feat\": pc_batch_1.voxel_tensor.features,\n",
    "    \"grid_coord\": pc_batch_1.voxel_tensor.indices[:, 1:],\n",
    "    \"batch\": pc_batch_1.voxel_tensor.indices[:, 0],\n",
    "    \"coord\": pc_batch_1.voxel_tensor.indices[:, 1:] * 0.01,\n",
    "    \"grid_size\": 0.01\n",
    "    # \"sparse_shape\": pc_batch_1.voxel_tensor.spatial_shape,\n",
    "    # \"sparse_conv_feat\": pc_batch_1.voxel_tensor,\n",
    "}\n",
    "outs = model(in_dict_1)\n",
    "# # print(model)\n",
    "# features = st.features\n",
    "# indices = st.indices\n",
    "# spatial_shape = st.spatial_shape\n",
    "# batch_size = st.batch_size\n",
    "\n",
    "# # Extract batch and grid coordinates from indices\n",
    "# batch = indices[:, 0]\n",
    "# grid_coord = indices[:, 1:]\n",
    "\n",
    "# # Construct the dictionary for initializing `Point`\n",
    "# input_dict = {\n",
    "#     \"feat\": features,\n",
    "#     \"grid_coord\": grid_coord,\n",
    "#     \"batch\": batch,\n",
    "#     \"sparse_shape\": spatial_shape,\n",
    "#     \"sparse_conv_feat\": st\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 64])\n"
     ]
    }
   ],
   "source": [
    "print(outs['feat'][pc_batch_1.pc_voxel_id].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = spconv.SparseConvTensor()\n",
    "ts.features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
