{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import open3d.ml.torch as ml3d\n",
    "from datasets.datasets_pair import *\n",
    "import spconv.pytorch as spconv\n",
    "import torch.optim as optim\n",
    "import functools\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform_reguliarzer(trans):\n",
    "    d = trans.size()[1] # k (bs, k, k)\n",
    "    I = torch.eye(d)[None, :, :] # no batch size\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda() # to cuda\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - I, dim=(1, 2))) # 尽可能满足正交性质\n",
    "    return loss\n",
    "\n",
    "def pixel_accuracy(pred, label):\n",
    "    correct = (pred == label).sum().item()\n",
    "    total = label.size  # 修改这里，从label.numel()改为label.size\n",
    "    return correct / total\n",
    "\n",
    "def mean_pixel_accuracy(pred, label, num_classes):\n",
    "    class_accuracies = []\n",
    "    for c in range(num_classes):\n",
    "        class_mask = (label == c)\n",
    "        if class_mask.sum().item() == 0:\n",
    "            continue\n",
    "        class_accuracy = (pred[class_mask] == c).sum().item() / class_mask.sum().item()\n",
    "        class_accuracies.append(class_accuracy)\n",
    "    return np.mean(class_accuracies)\n",
    "\n",
    "def intersection_over_union(pred, label, num_classes):\n",
    "    ious = []\n",
    "    for c in range(num_classes):\n",
    "        pred_class = (pred == c)\n",
    "        label_class = (label == c)\n",
    "        intersection = (pred_class & label_class).sum().item()\n",
    "        union = (pred_class | label_class).sum().item()\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # 如果没有出现这个类，则忽略\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    return np.array(ious)\n",
    "\n",
    "def mean_intersection_over_union(pred, label, num_classes):\n",
    "    ious = intersection_over_union(pred, label, num_classes)\n",
    "    return np.nanmean(ious)  # 忽略NaN值\n",
    "\n",
    "def frequency_weighted_intersection_over_union(pred, label, num_classes):\n",
    "    ious = intersection_over_union(pred, label, num_classes)\n",
    "    total = label.size  # 修改这里，从label.numel()改为label.size\n",
    "    class_freq = np.array([(label == c).sum().item() / total for c in range(num_classes)])\n",
    "    return (class_freq * ious).sum()\n",
    "\n",
    "# 示例调用\n",
    "# 假设 seg_1 是模型输出，labels_1 是标签\n",
    "def evaluate_segmentation_metrics(seg_1, labels_1):\n",
    "    # 将seg_1转化为预测标签\n",
    "    pred = torch.argmax(seg_1, dim=1)\n",
    "\n",
    "    # 将GPU tensor转化为CPU tensor，并转化为numpy数组\n",
    "    pred = pred.cpu().numpy()\n",
    "    labels_1 = labels_1.cpu().numpy()\n",
    "\n",
    "    num_classes = 2  # 假设只有两个类：背景和前景\n",
    "\n",
    "    pa = pixel_accuracy(pred, labels_1)\n",
    "    mpa = mean_pixel_accuracy(pred, labels_1, num_classes)\n",
    "    ious = intersection_over_union(pred, labels_1, num_classes)\n",
    "    miou = mean_intersection_over_union(pred, labels_1, num_classes)\n",
    "    fwiou = frequency_weighted_intersection_over_union(pred, labels_1, num_classes)\n",
    "\n",
    "    print(f\"Pixel Accuracy (PA): {pa:.4f}\")\n",
    "    print(f\"Mean Pixel Accuracy (MPA): {mpa:.4f}\")\n",
    "    print(f\"Intersection over Union (IoU) per class: {ious}\")\n",
    "    print(f\"Mean Intersection over Union (mIoU): {miou:.4f}\")\n",
    "    print(f\"Frequency Weighted Intersection over Union (FWIoU): {fwiou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33385\n",
      "806\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"./datasets/GAPartNet/dataset/data\"\n",
    "test_dir = \"/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra\"\n",
    "dataset_train = GAPartNetPair(\n",
    "                    Path(root_dir)  / \"pth\",\n",
    "                    Path(root_dir)  / \"meta\",\n",
    "                    shuffle=True,\n",
    "                    max_points=20000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=True, \n",
    "                    group_size = 2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    few_shot = False,\n",
    "                    few_shot_num=None,\n",
    "                    pos_jitter = 0.1,\n",
    "                    color_jitter = 0.3,\n",
    "                    flip_prob = 0.3,\n",
    "                    rotate_prob = 0.3,\n",
    "                )\n",
    "print(len(dataset_train))\n",
    "dataset_train[0]\n",
    "dataloader_train = DataLoader(\n",
    "                    dataset_train,\n",
    "                    batch_size=32,\n",
    "                    shuffle=True,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "dataset_test_inter = GAPartNetPair(\n",
    "                    Path(test_dir)  / \"pth\",\n",
    "                    Path(test_dir)  / \"meta\",\n",
    "                    glob_condition=\"/AKB*.pth\", \n",
    "                    shuffle=True,\n",
    "                    max_points=20000,\n",
    "                    augmentation=False,\n",
    "                    voxelization=True, \n",
    "                    with_pose=False,\n",
    "                    group_size = 2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    few_shot = False,\n",
    "                    few_shot_num=None,\n",
    "                    pos_jitter = 0.1,\n",
    "                    color_jitter = 0.3,\n",
    "                    flip_prob = 0.3,\n",
    "                    rotate_prob = 0.3,\n",
    "                )\n",
    "print(len(dataset_test_inter))\n",
    "dataset_test_inter[0]\n",
    "dataloader_test_inter = DataLoader(\n",
    "                    dataset_test_inter,\n",
    "                    batch_size=32,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based blocks\n",
    "class ResBlock(spconv.SparseModule):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, norm_fn: nn.Module, indice_key=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if in_channels == out_channels:\n",
    "            self.shortcut = nn.Identity() # channel 相同就是 x \n",
    "        else:\n",
    "            # assert False\n",
    "            self.shortcut = spconv.SparseSequential( # feature 层面的全连接\n",
    "                spconv.SubMConv3d(in_channels, out_channels, kernel_size=1, \\\n",
    "                bias=False),\n",
    "                norm_fn(out_channels),\n",
    "            )\n",
    "\n",
    "        self.conv1 = spconv.SparseSequential(\n",
    "            spconv.SubMConv3d(\n",
    "                in_channels, out_channels, kernel_size=3,\n",
    "                padding=1, bias=False, indice_key=indice_key,\n",
    "            ),\n",
    "            norm_fn(out_channels),\n",
    "        )\n",
    "\n",
    "        self.conv2 = spconv.SparseSequential(\n",
    "            spconv.SubMConv3d(\n",
    "                out_channels, out_channels, kernel_size=3,\n",
    "                padding=1, bias=False, indice_key=indice_key,\n",
    "            ),\n",
    "            norm_fn(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: spconv.SparseConvTensor) -> spconv.SparseConvTensor:\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = x.replace_feature(F.relu(x.features)) # 相当于ReLU\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = x.replace_feature(F.relu(x.features + shortcut.features))\n",
    "\n",
    "        return x\n",
    "\n",
    "class UBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: List[int],\n",
    "        block_fn: nn.Module,\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        indice_key_id: int = 1, # 递归计数器\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        encoder_blocks = [\n",
    "            block_fn(\n",
    "                channels[0], channels[0], norm_fn, indice_key=f\"subm{indice_key_id}\"\n",
    "            )\n",
    "            for _ in range(block_repeat)\n",
    "        ]\n",
    "        self.encoder_blocks = spconv.SparseSequential(*encoder_blocks) # 同层次几层\n",
    "\n",
    "        if len(channels) > 1:\n",
    "            self.downsample = spconv.SparseSequential(\n",
    "                spconv.SparseConv3d(\n",
    "                    channels[0], channels[1], kernel_size=2, stride=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[1]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            self.ublock = UBlock(\n",
    "                channels[1:], block_fn, block_repeat, norm_fn, indice_key_id + 1\n",
    "            ) # 这也能递归？？！\n",
    "\n",
    "            self.upsample = spconv.SparseSequential(\n",
    "                spconv.SparseInverseConv3d(\n",
    "                    channels[1], channels[0], kernel_size=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            decoder_blocks = [\n",
    "                block_fn(\n",
    "                    channels[0] * 2, channels[0], norm_fn,\n",
    "                    indice_key=f\"subm{indice_key_id}\",\n",
    "                ),\n",
    "            ]\n",
    "            for _ in range(block_repeat -1):\n",
    "                decoder_blocks.append(\n",
    "                    block_fn(\n",
    "                        channels[0], channels[0], norm_fn,\n",
    "                        indice_key=f\"subm{indice_key_id}\",\n",
    "                    )\n",
    "                )\n",
    "            self.decoder_blocks = spconv.SparseSequential(*decoder_blocks)\n",
    "\n",
    "    def forward(self, x: spconv.SparseConvTensor) -> spconv.SparseConvTensor:\n",
    "        x = self.encoder_blocks(x) # 平层过几次\n",
    "        shortcut = x\n",
    "\n",
    "        if len(self.channels) > 1: # 返回条件\n",
    "\n",
    "            x = self.downsample(x)\n",
    "            x = self.ublock(x) # 这也能递归？不愧是北大！艺术\n",
    "            x = self.upsample(x)\n",
    "\n",
    "            x = x.replace_feature(torch.cat([x.features, shortcut.features],\\\n",
    "                 dim=-1)) # shortcut\n",
    "            x = self.decoder_blocks(x) # 每层都有decoder_blocks, 因为cut了，所以feature * 2\n",
    "\n",
    "        return x\n",
    "    \n",
    "class SparseUNet(nn.Module):\n",
    "    def __init__(self, stem: nn.Module, ublock: UBlock):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = stem\n",
    "        self.ublock = ublock # 掉了一层壳子\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stem is not None:\n",
    "            x = self.stem(x)\n",
    "        x = self.ublock(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod # classmethod是个python特殊的方法\n",
    "    def build( # 相当于另一个构造函数\n",
    "        cls,\n",
    "        in_channels: int,\n",
    "        channels: List[int],\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        without_stem: bool = False,\n",
    "    ):\n",
    "        if not without_stem:\n",
    "            stem = spconv.SparseSequential(\n",
    "                spconv.SubMConv3d(\n",
    "                    in_channels, channels[0], kernel_size=3, # 把inchannel和channel对应上\n",
    "                    padding=1, bias=False, indice_key=\"subm1\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            stem = spconv.SparseSequential( # 通道一样就不管\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        block = UBlock(channels, ResBlock, block_repeat, norm_fn, \\\n",
    "            indice_key_id=1)\n",
    "\n",
    "        return SparseUNet(stem, block)\n",
    "\n",
    "class UBlock_NoSkip(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: List[int],\n",
    "        block_fn: nn.Module,\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        indice_key_id: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        encoder_blocks = [\n",
    "            block_fn(\n",
    "                channels[0], channels[0], norm_fn, indice_key=f\"subm{indice_key_id}\"\n",
    "            )\n",
    "            for _ in range(block_repeat)\n",
    "        ]\n",
    "        self.encoder_blocks = spconv.SparseSequential(*encoder_blocks)\n",
    "\n",
    "        if len(channels) > 1:\n",
    "            self.downsample = spconv.SparseSequential(\n",
    "                spconv.SparseConv3d(\n",
    "                    channels[0], channels[1], kernel_size=2, stride=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[1]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            self.ublock = UBlock(\n",
    "                channels[1:], block_fn, block_repeat, norm_fn, indice_key_id + 1\n",
    "            )\n",
    "\n",
    "            self.upsample = spconv.SparseSequential(\n",
    "                spconv.SparseInverseConv3d(\n",
    "                    channels[1], channels[0], kernel_size=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            decoder_blocks = [\n",
    "                block_fn(\n",
    "                    channels[0], channels[0], norm_fn,\n",
    "                    indice_key=f\"subm{indice_key_id}\",\n",
    "                ),\n",
    "            ]\n",
    "            for _ in range(block_repeat -1):\n",
    "                decoder_blocks.append(\n",
    "                    block_fn(\n",
    "                        channels[0], channels[0], norm_fn,\n",
    "                        indice_key=f\"subm{indice_key_id}\",\n",
    "                    )\n",
    "                )\n",
    "            self.decoder_blocks = spconv.SparseSequential(*decoder_blocks)\n",
    "\n",
    "    def forward(self, x: spconv.SparseConvTensor) -> spconv.SparseConvTensor:\n",
    "        x = self.encoder_blocks(x)\n",
    "        # shortcut = x\n",
    "\n",
    "        if len(self.channels) > 1:\n",
    "            x = self.downsample(x)\n",
    "            x = self.ublock(x)\n",
    "            x = self.upsample(x)\n",
    "\n",
    "            # x = x.replace_feature(torch.cat([x.features, shortcut.features],\\\n",
    "            #      dim=-1)) # 注释几行话而已\n",
    "            x = self.decoder_blocks(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SparseUNet_NoSkip(nn.Module): # 同理注释\n",
    "    def __init__(self, stem: nn.Module, ublock: UBlock_NoSkip):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = stem\n",
    "        self.ublock = ublock\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stem is not None:\n",
    "            x = self.stem(x)\n",
    "        x = self.ublock(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    def build(\n",
    "        cls,\n",
    "        in_channels: int,\n",
    "        channels: List[int],\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        without_stem: bool = False,\n",
    "    ):\n",
    "        if not without_stem:\n",
    "            stem = spconv.SparseSequential(\n",
    "                spconv.SubMConv3d(\n",
    "                    in_channels, channels[0], kernel_size=3,\n",
    "                    padding=1, bias=False, indice_key=\"subm1\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            stem = spconv.SparseSequential(\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        block = UBlock(channels, ResBlock, block_repeat, norm_fn, \\\n",
    "            indice_key_id=1)\n",
    "\n",
    "        return SparseUNet(stem, block)\n",
    "\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self, channel): # channel 看上去应该默认为3\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0] # (bs, features, points)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x))) # 一维卷积，放大features维度层次\n",
    "        x = torch.max(x, 2, keepdim=True)[0] # 点归并成最大features\n",
    "        x = x.view(-1, 1024) # 展平 \n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x))) # 连接到256层特征\n",
    "        x = self.fc3(x) # 9层\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(\n",
    "            batchsize, 1) # (bs, 1, 9) #[1 0 0]\n",
    "        if x.is_cuda: # is_cuda返回0     [0 1 0]\n",
    "            iden = iden.cuda() #          [0 0 1]\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3) # 预测的是一个单位阵，加上了一个矩阵\n",
    "        return x\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64): # 上升到了k维\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k) # 输出是k * k矩阵\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1, self.k * self.k).repeat(\n",
    "            batchsize, 1) # k维度单位阵\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, global_feat=True, feature_transform=False, channel=3):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.stn = STN3d(channel) # 3维\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64) # 特征也能变换\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, D, N = x.size()\n",
    "        trans = self.stn(x) # 矩阵\n",
    "        x = x.transpose(2, 1) # 交换 D, N，为了矩阵乘法\n",
    "        if D > 3: # 分割 features\n",
    "            feature = x[:, :, 3:]\n",
    "            x = x[:, :, :3]\n",
    "        x = torch.bmm(x, trans) # x 位置进行变换\n",
    "        if D > 3:\n",
    "            x = torch.cat([x, feature], dim=2)\n",
    "        x = x.transpose(2, 1) # 变回来\n",
    "        x = F.relu(self.bn1(self.conv1(x))) # 增广D\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat) # 变换features\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x # shortcut\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0] # 增广，features取N上面的最大\n",
    "        x = x.view(-1, 1024) # 展平\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat # 返回的本质是1024feature和\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, N) # (bs, 1024, N) N个是一样的\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat # 决定是否concat，增广是为了concat\n",
    "\n",
    "class PointNetSegBackbone(nn.Module):\n",
    "    def __init__(self, pc_dim, fea_dim):\n",
    "        super(PointNetSegBackbone, self).__init__()\n",
    "        self.fea_dim = fea_dim\n",
    "        self.feat = PointNetEncoder(global_feat=False, feature_transform=True, channel=3+pc_dim)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1) # 1024 + 64 feature位置\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 256, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(256, self.fea_dim, 1) # 干到输出的features\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x) # 给feature降维 \n",
    "        fea = x.transpose(2,1).contiguous() # D, N 换位\n",
    "        return fea\n",
    "        # x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        # x = x.view(batchsize, n_pts, self.k)\n",
    "        # return x, trans_feat\n",
    "\n",
    "class get_loss(torch.nn.Module):\n",
    "    def __init__(self, mat_diff_loss_scale=0.001):\n",
    "        super(get_loss, self).__init__()\n",
    "        self.mat_diff_loss_scale = mat_diff_loss_scale\n",
    "\n",
    "    def forward(self, pred, target, trans_feat, weight):\n",
    "        loss = F.nll_loss(pred, target, weight = weight) # ?\n",
    "        mat_diff_loss = feature_transform_reguliarzer(trans_feat) # 正交损失\n",
    "        total_loss = loss + mat_diff_loss * self.mat_diff_loss_scale # 你也没返回loss啊\n",
    "\n",
    "class PointNetBackbone(nn.Module): # 这个就是把pointnet包调出来\n",
    "    def __init__(\n",
    "        self,\n",
    "        pc_dim: int,\n",
    "        feature_dim: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pc_dim = pc_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.backbone = PointNetSegBackbone(self.pc_dim,self.feature_dim)\n",
    "    \n",
    "    def forward(self, input_pc):\n",
    "        others = {}\n",
    "        return self.backbone(input_pc), others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seg_test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sparseunet = SparseUNet.build(6, [16, 32, 48, 64, 80, 96, 112], 2, functools.partial(nn.BatchNorm1d, eps=1e-4, momentum=0.1))\n",
    "        self.sem_seg_head = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, pc_batch_1: PointCloudBatch, pc_batch_2: PointCloudBatch):\n",
    "        voxel_tensor_1 = pc_batch_1.voxel_tensor\n",
    "        pc_voxel_id_1 = pc_batch_1.pc_voxel_id\n",
    "        voxel_features = self.sparseunet(voxel_tensor_1)\n",
    "        pc_feature_1 = voxel_features.features[pc_voxel_id_1]\n",
    "\n",
    "        voxel_tensor_2 = pc_batch_2.voxel_tensor\n",
    "        pc_voxel_id_2 = pc_batch_2.pc_voxel_id\n",
    "        voxel_features = self.sparseunet(voxel_tensor_2)\n",
    "        pc_feature_2 = voxel_features.features[pc_voxel_id_2]\n",
    "\n",
    "        seg_1 = self.sem_seg_head(pc_feature_1)\n",
    "        seg_2 = self.sem_seg_head(pc_feature_2)\n",
    "\n",
    "        return seg_1, seg_2\n",
    "\n",
    "\n",
    "def train(model: Seg_test, dataloader_train: DataLoader, epoch: int = 5, lr: float = 0.001, device: torch.device = \"cuda:0\"):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for e in range(epoch):\n",
    "        running_loss = 0.0\n",
    "        for i, inputs in enumerate(dataloader_train):\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            \n",
    "            # 从inputs中提取两个点云列表，并进行collate操作\n",
    "            pc_b_1 = [pc_pair.pc1 for pc_pair in inputs]\n",
    "            pc_b_2 = [pc_pair.pc2 for pc_pair in inputs]\n",
    "            \n",
    "            pc_batch_1 = PointCloud.collate(pc_b_1)\n",
    "            pc_batch_2 = PointCloud.collate(pc_b_2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            seg_1, seg_2 = model(pc_batch_1, pc_batch_2)\n",
    "            \n",
    "            labels_1 = pc_batch_1.sem_labels.to(device)\n",
    "            labels_2 = pc_batch_2.sem_labels.to(device)\n",
    "            \n",
    "            labels_1[labels_1 > 0] = 1\n",
    "            labels_2[labels_2 > 0] = 1\n",
    "            \n",
    "            loss_1 = criterion(seg_1, labels_1)\n",
    "            loss_2 = criterion(seg_2, labels_2)\n",
    "            \n",
    "            loss = loss_1 + loss_2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if i % 10 == 9:  # 每10个batch打印一次损失\n",
    "                print(f\"Epoch [{e + 1}/{epoch}], Batch [{i + 1}], Loss: {running_loss / 10:.4f}\")\n",
    "                running_loss = 0.0\n",
    "\n",
    "        print(f\"Epoch [{e + 1}/{epoch}] completed.\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "def test(model: Seg_test, dataloader_test: DataLoader, device: torch.device = torch.device(\"cuda:0\"), limit_length = 500):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in enumerate(dataloader_test):\n",
    "            if i > limit_length:\n",
    "                break\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "\n",
    "            # 从inputs中提取两个点云列表，并进行collate操作\n",
    "            pc_b_1 = [pc_pair.pc1 for pc_pair in inputs]\n",
    "            pc_b_2 = [pc_pair.pc2 for pc_pair in inputs]\n",
    "\n",
    "            pc_batch_1 = PointCloud.collate(pc_b_1)\n",
    "            pc_batch_2 = PointCloud.collate(pc_b_2)\n",
    "\n",
    "            seg_1, seg_2 = model(pc_batch_1, pc_batch_2)\n",
    "\n",
    "            labels_1 = pc_batch_1.sem_labels.to(device)\n",
    "            labels_2 = pc_batch_2.sem_labels.to(device)\n",
    "\n",
    "            # 将标签中的非零值转换为1\n",
    "            labels_1[labels_1 > 0] = 1\n",
    "            labels_2[labels_2 > 0] = 1\n",
    "\n",
    "            # 计算损失\n",
    "            loss_1 = criterion(seg_1, labels_1)\n",
    "            loss_2 = criterion(seg_2, labels_2)\n",
    "            \n",
    "            loss = loss_1 + loss_2\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # 收集所有预测和标签用于后续的评价指标计算\n",
    "            all_preds.append(seg_1)\n",
    "            all_labels.append(labels_1)\n",
    "\n",
    "    # 计算平均损失\n",
    "    avg_loss = running_loss / len(dataloader_test)\n",
    "\n",
    "    # 将所有预测和标签拼接在一起\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # 计算评价指标\n",
    "    evaluate_segmentation_metrics(all_preds, all_labels)\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seg_test().cuda()\n",
    "model.load_state_dict(torch.load(\"./log_dir/seg_test/Epoch[51|100]_Batch[1044]_Loss:0.0328.pth\"))\n",
    "# print(model)\n",
    "# train(model, dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________test__________inter_____________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Accuracy (PA): 0.9497\n",
      "Mean Pixel Accuracy (MPA): 0.9253\n",
      "Intersection over Union (IoU) per class: [0.93204187 0.8378111 ]\n",
      "Mean Intersection over Union (mIoU): 0.8849\n",
      "Frequency Weighted Intersection over Union (FWIoU): 0.9037\n",
      "Test Loss: 0.3557\n",
      "________________test__________intra_____________\n",
      "Pixel Accuracy (PA): 0.9878\n",
      "Mean Pixel Accuracy (MPA): 0.9824\n",
      "Intersection over Union (IoU) per class: [0.98326561 0.95716555]\n",
      "Mean Intersection over Union (mIoU): 0.9702\n",
      "Frequency Weighted Intersection over Union (FWIoU): 0.9759\n",
      "Test Loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "# model = Seg_test().cuda()\n",
    "# print(model)\n",
    "# model.load_state_dict(torch.load(\"./log_dir/seg_test/Epoch[51|100]_Batch[1044]_Loss:0.0328.pth\"))\n",
    "# inputs = next(iter(dataloader_train))\n",
    "# inputs = [i.to(\"cuda:0\") for i in inputs]\n",
    "# pc_b_1 = [pc_pair.pc1 for pc_pair in inputs]\n",
    "# pc_b_2 = [pc_pair.pc2 for pc_pair in inputs]\n",
    "# pc_batch_1 = PointCloud.collate(pc_b_1)\n",
    "# pc_batch_2 = PointCloud.collate(pc_b_2)\n",
    "# seg_1, seg_2 = model(pc_batch_1, pc_batch_2)\n",
    "# print(seg_1.shape)\n",
    "# print(seg_2.shape)\n",
    "# labels_1 = pc_batch_1.sem_labels\n",
    "# labels_2 = pc_batch_2.sem_labels\n",
    "# labels_1[labels_1 > 0] = 1\n",
    "# labels_2[labels_2 > 0] = 1\n",
    "# evaluate_segmentation_metrics(seg_1, labels_1)\n",
    "# evaluate_segmentation_metrics(seg_2, labels_2)\n",
    "print(\"________________test__________inter_____________\")\n",
    "test(model, dataloader_test_inter, \"cuda:0\", 50)\n",
    "print(\"________________test__________intra_____________\")\n",
    "test(model, dataloader_train, \"cuda:0\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n",
      "no rotation to use. \n",
      "25491\n"
     ]
    }
   ],
   "source": [
    "from visu import *\n",
    "for datasets in [dataset_test_inter, dataset_train]:\n",
    "    i = random.randint(0, len(datasets))\n",
    "    print(i)\n",
    "    # print(dataset_test_inter.group_files[5][0])\n",
    "    # print(dataset_test_inter[5].pc1)\n",
    "    name = datasets.group_files[i][0].split('/')[-1].split('.')[0]\n",
    "    inputs = [datasets[i]]\n",
    "    inputs = [inp.to(\"cuda:0\") for inp in inputs]\n",
    "    pc_b_1 = [pc_pair.pc1 for pc_pair in inputs]\n",
    "    pc_b_2 = [pc_pair.pc2 for pc_pair in inputs]\n",
    "    pc_batch_1 = PointCloud.collate(pc_b_1)\n",
    "    pc_batch_2 = PointCloud.collate(pc_b_2)\n",
    "    sem_pred = model(pc_batch_1, pc_batch_2)[0]\n",
    "    sem_pred = torch.argmax(sem_pred, dim=1)\n",
    "    five = (datasets == dataset_test_inter)\n",
    "    if five:\n",
    "        dir_name = test_dir\n",
    "    else:\n",
    "        dir_name = root_dir\n",
    "    # print(sem_pred.shape)\n",
    "    # visualize_gapartnet(\"./log_dir/seg_test/visu\", root_dir, None, ['sem_gt', 'pc', 'world_gt', 'sem_pred'], name, sem_preds = sem_pred.detach().cpu())\n",
    "    visualize_gapartnet(\"./log_dir/seg_test/visu\", dir_name, None, ['sem_gt', 'pc', 'world_gt', 'sem_pred'], name, sem_preds = sem_pred.detach().cpu(), five=five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '.' + \"/seg_test_SpuNet_half_epoch.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 104])\n"
     ]
    }
   ],
   "source": [
    "inputs = next(iter(dataloader_train))\n",
    "pc_b_1 = [pc_pair.pc1 for pc_pair in inputs]\n",
    "pc_batch_1 = PointCloud.collate(pc_b_1)\n",
    "print(pc_batch_1.instance_sem_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 5,  ..., 0, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "print(pc_batch_1.sem_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_300_00_020.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_213_00_010.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_60_00_005.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_283_00_014.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_294_00_025.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_294_00_014.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_289_00_014.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_1_00_028.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_63_00_006.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_45_00_025.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_3_00_026.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_55_00_013.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_282_00_025.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_55_00_022.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_283_00_007.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_3_00_016.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_213_00_021.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_5_00_028.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_219_00_030.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_224_00_006.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_64_00_012.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_3_00_018.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_4_00_028.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_55_00_021.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_64_00_028.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_224_00_017.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_4_00_026.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_283_00_013.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_63_00_024.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_64_00_021.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_289_00_013.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_5_00_003.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_283_00_031.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_58_00_016.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_63_00_004.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_288_00_000.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_5_00_023.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_45_00_029.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_2_00_007.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_283_00_024.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_1_00_010.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBox_58_00_017.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_2_00_027.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_225_00_027.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_225_00_008.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_5_00_029.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBDrawer_294_00_011.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_2_00_012.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBTrashCan_224_00_021.pth', '/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/pth/AKBBucket_1_00_030.pth']\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"./datasets/GAPartNet/dataset/data/\"\n",
    "test_dir = \"/16T/zhangran/GAPartNet-release/gapartnet/data/GAPartNet_All/test_intra/\"\n",
    "file_paths=glob(str(test_dir + \"pth\") + \"/AKB*.pth\")\n",
    "print(file_paths[0:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
