{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# import \n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.adam as adam\n",
    "import math\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "import torch.optim as optim\n",
    "import functools\n",
    "from torch.autograd import Variable\n",
    "import open3d.ml.torch as ml3d\n",
    "from datasets.datasets_pair import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchmetrics\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# util function\n",
    "def get_neighbor_index(vertices: \"(bs, vertice_num, 3)\", neighbor_num: int):\n",
    "    \"\"\"\n",
    "    Return: (bs, vertice_num, neighbor_num)\n",
    "    \"\"\"\n",
    "    bs, v, _ = vertices.size()\n",
    "    device = vertices.device\n",
    "    inner = torch.bmm(vertices, vertices.transpose(1, 2))  # (bs, v, v)\n",
    "    quadratic = torch.sum(vertices ** 2, dim=2)  # (bs, v)\n",
    "    distance = inner * (-2) + quadratic.unsqueeze(1) + quadratic.unsqueeze(2)\n",
    "    neighbor_index = torch.topk(distance, k=neighbor_num + 1, dim=-1, largest=False)[1]\n",
    "    neighbor_index = neighbor_index[:, :, 1:]\n",
    "    return neighbor_index\n",
    "\n",
    "\n",
    "def get_nearest_index(target: \"(bs, v1, 3)\", source: \"(bs, v2, 3)\"):\n",
    "    \"\"\"\n",
    "    Return: (bs, v1, 1)\n",
    "    \"\"\"\n",
    "    inner = torch.bmm(target, source.transpose(1, 2))  # (bs, v1, v2)\n",
    "    s_norm_2 = torch.sum(source ** 2, dim=2)  # (bs, v2)\n",
    "    t_norm_2 = torch.sum(target ** 2, dim=2)  # (bs, v1)\n",
    "    d_norm_2 = s_norm_2.unsqueeze(1) + t_norm_2.unsqueeze(2) - 2 * inner\n",
    "    nearest_index = torch.topk(d_norm_2, k=1, dim=-1, largest=False)[1]\n",
    "    return nearest_index\n",
    "\n",
    "\n",
    "def indexing_neighbor(tensor: \"(bs, vertice_num, dim)\", index: \"(bs, vertice_num, neighbor_num)\"):\n",
    "    \"\"\"\n",
    "    Return: (bs, vertice_num, neighbor_num, dim)\n",
    "    \"\"\"\n",
    "\n",
    "    bs, v, n = index.size()\n",
    "\n",
    "    # ss = time.time()\n",
    "    if bs == 1:\n",
    "        # id_0 = torch.arange(bs).view(-1, 1,1)\n",
    "        tensor_indexed = tensor[torch.Tensor([[0]]).long(), index[0]].unsqueeze(dim=0)\n",
    "    else:\n",
    "        id_0 = torch.arange(bs).view(-1, 1, 1).long()\n",
    "        tensor_indexed = tensor[id_0, index]\n",
    "    # ee = time.time()\n",
    "    # print('tensor_indexed time: ', str(ee - ss))\n",
    "    return tensor_indexed\n",
    "\n",
    "\n",
    "def get_neighbor_direction_norm(vertices: \"(bs, vertice_num, 3)\", neighbor_index: \"(bs, vertice_num, neighbor_num)\"):\n",
    "    \"\"\"\n",
    "    Return: (bs, vertice_num, neighobr_num, 3)\n",
    "    \"\"\"\n",
    "    # ss = time.time()\n",
    "    neighbors = indexing_neighbor(vertices, neighbor_index)  # (bs, v, n, 3)\n",
    "\n",
    "    neighbor_direction = neighbors - vertices.unsqueeze(2)\n",
    "    neighbor_direction_norm = F.normalize(neighbor_direction, dim=-1)\n",
    "    return neighbor_direction_norm.float()\n",
    "\n",
    "\n",
    "def get_gt_v(Rs, axis=2):\n",
    "    bs = Rs.shape[0]  # bs x 3 x 3\n",
    "    # TODO use 3 axis, the order remains: do we need to change order?\n",
    "    if axis == 3:\n",
    "        corners = torch.tensor([[0, 0, 1], [0, 1, 0], [1, 0, 0]], dtype=torch.float).to(Rs.device)\n",
    "        corners = corners.view(1, 3, 3).repeat(bs, 1, 1)  # bs x 3 x 3\n",
    "        gt_vec = torch.bmm(Rs, corners).transpose(2, 1).reshape(bs, -1)\n",
    "    else:\n",
    "        assert axis == 2\n",
    "        corners = torch.tensor([[0, 0, 1], [0, 1, 0], [0, 0, 0]], dtype=torch.float).to(Rs.device)\n",
    "        corners = corners.view(1, 3, 3).repeat(bs, 1, 1)  # bs x 3 x 3\n",
    "        gt_vec = torch.bmm(Rs, corners).transpose(2, 1).reshape(bs, -1)\n",
    "    gt_green = gt_vec[:, 3:6]\n",
    "    gt_red = gt_vec[:, (6, 7, 8)]\n",
    "    return gt_green, gt_red\n",
    "\n",
    "# gcn3d layers\n",
    "class Conv_surface(nn.Module):\n",
    "    \"\"\"Extract structure feafure from surface, independent from vertice coordinates\"\"\"\n",
    "\n",
    "    def __init__(self, kernel_num, support_num):\n",
    "        super().__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.support_num = support_num\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.directions = nn.Parameter(torch.FloatTensor(3, support_num * kernel_num))\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        stdv = 1. / math.sqrt(self.support_num * self.kernel_num)\n",
    "        self.directions.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self,\n",
    "                neighbor_index: \"(bs, vertice_num, neighbor_num)\",\n",
    "                vertices: \"(bs, vertice_num, 3)\"):\n",
    "        \"\"\"\n",
    "        Return vertices with local feature: (bs, vertice_num, kernel_num)\n",
    "        \"\"\"\n",
    "        bs, vertice_num, neighbor_num = neighbor_index.size()\n",
    "        # ss = time.time()\n",
    "        neighbor_direction_norm = get_neighbor_direction_norm(vertices, neighbor_index)\n",
    "\n",
    "        # R = get_rotation(0,0,0)\n",
    "        # R = torch.from_numpy(R).cuda()\n",
    "        # R = R.unsqueeze(0).repeat(bs,1,1).float() ## bs 3,3\n",
    "        # vertices2 = torch.bmm(R,vertices.transpose(1,2)).transpose(2,1)\n",
    "        # neighbor_direction_norm2 = get_neighbor_direction_norm(vertices2, neighbor_index)\n",
    "\n",
    "        support_direction_norm = F.normalize(self.directions, dim=0)  # (3, s * k)\n",
    "\n",
    "        theta = neighbor_direction_norm @ support_direction_norm  # (bs, vertice_num, neighbor_num, s*k)\n",
    "\n",
    "        theta = self.relu(theta)\n",
    "        theta = theta.contiguous().view(bs, vertice_num, neighbor_num, self.support_num, self.kernel_num)\n",
    "        theta = torch.max(theta, dim=2)[0]  # (bs, vertice_num, support_num, kernel_num)\n",
    "        feature = torch.sum(theta, dim=2)  # (bs, vertice_num, kernel_num)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class Conv_layer(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, support_num):\n",
    "        super().__init__()\n",
    "        # arguments:\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.support_num = support_num\n",
    "\n",
    "        # parameters:\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.weights = nn.Parameter(torch.FloatTensor(in_channel, (support_num + 1) * out_channel))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor((support_num + 1) * out_channel))\n",
    "        self.directions = nn.Parameter(torch.FloatTensor(3, support_num * out_channel))\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        stdv = 1. / math.sqrt(self.out_channel * (self.support_num + 1))\n",
    "        self.weights.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "        self.directions.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self,\n",
    "                neighbor_index: \"(bs, vertice_num, neighbor_index)\",\n",
    "                vertices: \"(bs, vertice_num, 3)\",\n",
    "                feature_map: \"(bs, vertice_num, in_channel)\"):\n",
    "        \"\"\"\n",
    "        Return: output feature map: (bs, vertice_num, out_channel)\n",
    "        \"\"\"\n",
    "        bs, vertice_num, neighbor_num = neighbor_index.size()\n",
    "        neighbor_direction_norm = get_neighbor_direction_norm(vertices, neighbor_index)\n",
    "        support_direction_norm = F.normalize(self.directions, dim=0)\n",
    "        theta = neighbor_direction_norm @ support_direction_norm  # (bs, vertice_num, neighbor_num, support_num * out_channel)\n",
    "        theta = self.relu(theta)\n",
    "        theta = theta.contiguous().view(bs, vertice_num, neighbor_num, -1)\n",
    "        # (bs, vertice_num, neighbor_num, support_num * out_channel)\n",
    "\n",
    "        feature_out = feature_map @ self.weights + self.bias  # (bs, vertice_num, (support_num + 1) * out_channel)\n",
    "        feature_center = feature_out[:, :, :self.out_channel]  # (bs, vertice_num, out_channel)\n",
    "        feature_support = feature_out[:, :, self.out_channel:]  # (bs, vertice_num, support_num * out_channel)\n",
    "\n",
    "        # Fuse together - max among product\n",
    "        feature_support = indexing_neighbor(feature_support,\n",
    "                                            neighbor_index)  # (bs, vertice_num, neighbor_num, support_num * out_channel)\n",
    "        activation_support = theta * feature_support  # (bs, vertice_num, neighbor_num, support_num * out_channel)\n",
    "        activation_support = activation_support.view(bs, vertice_num, neighbor_num, self.support_num, self.out_channel)\n",
    "        activation_support = torch.max(activation_support, dim=2)[0]  # (bs, vertice_num, support_num, out_channel)\n",
    "        activation_support = torch.sum(activation_support, dim=2)  # (bs, vertice_num, out_channel)\n",
    "        feature_fuse = feature_center + activation_support  # (bs, vertice_num, out_channel)\n",
    "        return feature_fuse\n",
    "\n",
    "\n",
    "class Pool_layer(nn.Module):\n",
    "    def __init__(self, pooling_rate: int = 4, neighbor_num: int = 4):\n",
    "        super().__init__()\n",
    "        self.pooling_rate = pooling_rate\n",
    "        self.neighbor_num = neighbor_num\n",
    "\n",
    "    def forward(self,\n",
    "                vertices: \"(bs, vertice_num, 3)\",\n",
    "                feature_map: \"(bs, vertice_num, channel_num)\"):\n",
    "        \"\"\"\n",
    "        Return:\n",
    "            vertices_pool: (bs, pool_vertice_num, 3),\n",
    "            feature_map_pool: (bs, pool_vertice_num, channel_num)\n",
    "        \"\"\"\n",
    "        bs, vertice_num, _ = vertices.size()\n",
    "        neighbor_index = get_neighbor_index(vertices, self.neighbor_num)\n",
    "        neighbor_feature = indexing_neighbor(feature_map,\n",
    "                                             neighbor_index)  # (bs, vertice_num, neighbor_num, channel_num)\n",
    "        pooled_feature = torch.max(neighbor_feature, dim=2)[0]  # (bs, vertice_num, channel_num)\n",
    "\n",
    "        pool_num = int(vertice_num / self.pooling_rate)\n",
    "        sample_idx = torch.randperm(vertice_num)[:pool_num]\n",
    "        vertices_pool = vertices[:, sample_idx, :]  # (bs, pool_num, 3)\n",
    "        feature_map_pool = pooled_feature[:, sample_idx, :]  # (bs, pool_num, channel_num)\n",
    "        return vertices_pool, feature_map_pool\n",
    "    \n",
    "# posenet layers\n",
    "class Rot_green(nn.Module):\n",
    "    def __init__(self, feat_c_R, R_c):\n",
    "        super(Rot_green, self).__init__()\n",
    "        self.f = feat_c_R\n",
    "        self.k = R_c\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(self.f, 1024, 1)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv1d(1024, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 256, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(256, self.k, 1)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.squeeze(2)\n",
    "        x = x.contiguous()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Rot_red(nn.Module):\n",
    "    def __init__(self, feat_c_R, R_c):\n",
    "        super(Rot_red, self).__init__()\n",
    "        self.f = feat_c_R\n",
    "        self.k = R_c\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(self.f, 1024, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(1024, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 256, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(256, self.k, 1)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.squeeze(2)\n",
    "        x = x.contiguous()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Pose_Ts(nn.Module):\n",
    "    def __init__(self, feat_c_ts, Ts_c):\n",
    "        super(Pose_Ts, self).__init__()\n",
    "        self.f = feat_c_ts\n",
    "        self.k = Ts_c\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(self.f, 1024, 1)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv1d(1024, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 256, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(256, self.k, 1)\n",
    "        self.drop1 = nn.Dropout(0.2)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.squeeze(2)\n",
    "        x = x.contiguous()\n",
    "        xt = x[:, 0:3]\n",
    "        xs = x[:, 3:6]\n",
    "        return xt, xs\n",
    "    \n",
    "\n",
    "class FaceRecon(nn.Module):\n",
    "    def __init__(self, gcn_n_num, gcn_sup_num, face_recon_c, obj_c, feat_face):\n",
    "        super(FaceRecon, self).__init__()\n",
    "        self.neighbor_num = gcn_n_num\n",
    "        self.support_num = gcn_sup_num\n",
    "\n",
    "        # 3D convolution for point cloud\n",
    "        self.conv_0 = Conv_surface(kernel_num=128, support_num=self.support_num)\n",
    "        self.conv_1 = Conv_layer(128, 128, support_num=self.support_num)\n",
    "        self.pool_1 = Pool_layer(pooling_rate=4, neighbor_num=4)\n",
    "        self.conv_2 = Conv_layer(128, 256, support_num=self.support_num)\n",
    "        self.conv_3 = Conv_layer(256, 256, support_num=self.support_num)\n",
    "        self.pool_2 = Pool_layer(pooling_rate=4, neighbor_num=4)\n",
    "        self.conv_4 = Conv_layer(256, 512, support_num=self.support_num)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.recon_num = 3\n",
    "        self.face_recon_num = face_recon_c\n",
    "        self.obj_c = obj_c\n",
    "        \n",
    "        dim_fuse = sum([128, 128, 256, 256, 512, obj_c])\n",
    "        # 16: total 6 categories, 256 is global feature\n",
    "        self.conv1d_block = nn.Sequential(\n",
    "            nn.Conv1d(dim_fuse, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.recon_head = nn.Sequential(\n",
    "            nn.Conv1d(256, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, self.recon_num, 1),\n",
    "        )\n",
    "\n",
    "        self.face_head = nn.Sequential(\n",
    "            nn.Conv1d(feat_face + 3, 512, 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 256, 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 128, 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, self.face_recon_num, 1),  # Relu or not?\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                vertices: \"tensor (bs, vetice_num, 3)\",\n",
    "                cat_id: \"tensor (bs, 1)\",\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Return: (bs, vertice_num, class_num)\n",
    "        \"\"\"\n",
    "        #  concate feature\n",
    "        bs, vertice_num, _ = vertices.size()\n",
    "        # cat_id to one-hot\n",
    "        if cat_id.shape[0] == 1:\n",
    "            obj_idh = cat_id.view(-1, 1).repeat(cat_id.shape[0], 1)\n",
    "        else:\n",
    "            obj_idh = cat_id.view(-1, 1)\n",
    "\n",
    "        one_hot = torch.zeros(bs, self.obj_c).to(cat_id.device).scatter_(1, obj_idh.long(), 1)\n",
    "        # bs x verticenum x 6\n",
    "\n",
    "        neighbor_index = get_neighbor_index(vertices, self.neighbor_num)\n",
    "        # ss = time.time()\n",
    "        fm_0 = F.relu(self.conv_0(neighbor_index, vertices), inplace=True)\n",
    "\n",
    "        fm_1 = F.relu(self.bn1(self.conv_1(neighbor_index, vertices, fm_0).transpose(1, 2)).transpose(1, 2),\n",
    "                      inplace=True)\n",
    "        v_pool_1, fm_pool_1 = self.pool_1(vertices, fm_1)\n",
    "        # neighbor_index = get_neighbor_index(v_pool_1, self.neighbor_num)\n",
    "        neighbor_index = get_neighbor_index(v_pool_1,\n",
    "                                                  min(self.neighbor_num, v_pool_1.shape[1] // 8))\n",
    "        fm_2 = F.relu(self.bn2(self.conv_2(neighbor_index, v_pool_1, fm_pool_1).transpose(1, 2)).transpose(1, 2),\n",
    "                      inplace=True)\n",
    "        fm_3 = F.relu(self.bn3(self.conv_3(neighbor_index, v_pool_1, fm_2).transpose(1, 2)).transpose(1, 2),\n",
    "                      inplace=True)\n",
    "        v_pool_2, fm_pool_2 = self.pool_2(v_pool_1, fm_3)\n",
    "        # neighbor_index = get_neighbor_index(v_pool_2, self.neighbor_num)\n",
    "        neighbor_index = get_neighbor_index(v_pool_2, min(self.neighbor_num,\n",
    "                                                                v_pool_2.shape[1] // 8))\n",
    "        fm_4 = self.conv_4(neighbor_index, v_pool_2, fm_pool_2)\n",
    "        f_global = fm_4.max(1)[0]  # (bs, f)\n",
    "\n",
    "        nearest_pool_1 = get_nearest_index(vertices, v_pool_1)\n",
    "        nearest_pool_2 = get_nearest_index(vertices, v_pool_2)\n",
    "        fm_2 = indexing_neighbor(fm_2, nearest_pool_1).squeeze(2)\n",
    "        fm_3 = indexing_neighbor(fm_3, nearest_pool_1).squeeze(2)\n",
    "        fm_4 = indexing_neighbor(fm_4, nearest_pool_2).squeeze(2)\n",
    "        one_hot = one_hot.unsqueeze(1).repeat(1, vertice_num, 1)  # (bs, vertice_num, cat_one_hot)\n",
    "\n",
    "        feat = torch.cat([fm_0, fm_1, fm_2, fm_3, fm_4, one_hot], dim=2)\n",
    "        '''\n",
    "        feat_face = torch.cat([fm_0, fm_1, fm_2, fm_3, fm_4], dim=2)\n",
    "        feat_face = torch.mean(feat_face, dim=1, keepdim=True)  # bs x 1 x channel\n",
    "        feat_face_re = feat_face.repeat(1, feat.shape[1], 1)\n",
    "        '''\n",
    "        # feat_face_re = self.global_perception_head(feat)  # bs x C x 1\n",
    "        feat_face_re = f_global.view(bs, 1, f_global.shape[1]).repeat(1, feat.shape[1], 1).permute(0, 2, 1)\n",
    "        # feat is the extracted per pixel level feature\n",
    "\n",
    "        conv1d_input = feat.permute(0, 2, 1)  # (bs, fuse_ch, vertice_num)\n",
    "        conv1d_out = self.conv1d_block(conv1d_input)\n",
    "\n",
    "        recon = self.recon_head(conv1d_out)\n",
    "        # average pooling for face prediction\n",
    "        feat_face_in = torch.cat([feat_face_re, conv1d_out, vertices.permute(0, 2, 1)], dim=1)\n",
    "        face = self.face_head(feat_face_in)\n",
    "        return recon.permute(0, 2, 1), face.permute(0, 2, 1), feat\n",
    "    \n",
    "# postnet9d\n",
    "class FaceRecon_feat(nn.Module):\n",
    "    def __init__(self, gcn_n_num, gcn_sup_num):\n",
    "        super(FaceRecon_feat, self).__init__()\n",
    "        self.neighbor_num = gcn_n_num\n",
    "        self.support_num = gcn_sup_num\n",
    "\n",
    "        # 3D convolution for point cloud\n",
    "        self.conv_0 = Conv_surface(kernel_num=128, support_num=self.support_num)\n",
    "        self.conv_1 = Conv_layer(128, 128, support_num=self.support_num)\n",
    "        self.pool_1 = Pool_layer(pooling_rate=4, neighbor_num=4)\n",
    "        self.conv_2 = Conv_layer(128, 256, support_num=self.support_num)\n",
    "        self.conv_3 = Conv_layer(256, 256, support_num=self.support_num)\n",
    "        self.pool_2 = Pool_layer(pooling_rate=4, neighbor_num=4)\n",
    "        self.conv_4 = Conv_layer(256, 512, support_num=self.support_num)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self,\n",
    "                vertices: \"tensor (bs, vetice_num, 3)\",\n",
    "                # cat_id: \"tensor (bs, 1)\",\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Return: (bs, vertice_num, class_num)\n",
    "        \"\"\"\n",
    "\n",
    "        neighbor_index = get_neighbor_index(vertices, self.neighbor_num)\n",
    "        fm_0 = F.relu(self.conv_0(neighbor_index, vertices), inplace=True)\n",
    "\n",
    "        fm_1 = F.relu(self.bn1(self.conv_1(neighbor_index, vertices, fm_0).transpose(1, 2)).transpose(1, 2),\n",
    "                      inplace=True)\n",
    "        v_pool_1, fm_pool_1 = self.pool_1(vertices, fm_1)\n",
    "        neighbor_index = get_neighbor_index(v_pool_1,\n",
    "                                                  min(self.neighbor_num, v_pool_1.shape[1] // 8))\n",
    "        fm_2 = F.relu(self.bn2(self.conv_2(neighbor_index, v_pool_1, fm_pool_1).transpose(1, 2)).transpose(1, 2),\n",
    "                      inplace=True)\n",
    "        fm_3 = F.relu(self.bn3(self.conv_3(neighbor_index, v_pool_1, fm_2).transpose(1, 2)).transpose(1, 2),\n",
    "                      inplace=True)\n",
    "        v_pool_2, fm_pool_2 = self.pool_2(v_pool_1, fm_3)\n",
    "        neighbor_index = get_neighbor_index(v_pool_2, min(self.neighbor_num,\n",
    "                                                                v_pool_2.shape[1] // 8))\n",
    "        fm_4 = self.conv_4(neighbor_index, v_pool_2, fm_pool_2)\n",
    "        nearest_pool_1 = get_nearest_index(vertices, v_pool_1)\n",
    "        nearest_pool_2 = get_nearest_index(vertices, v_pool_2)\n",
    "        fm_2 = indexing_neighbor(fm_2, nearest_pool_1).squeeze(2)\n",
    "        fm_3 = indexing_neighbor(fm_3, nearest_pool_1).squeeze(2)\n",
    "        fm_4 = indexing_neighbor(fm_4, nearest_pool_2).squeeze(2)\n",
    "\n",
    "        feat = torch.cat([fm_0, fm_1, fm_2, fm_3, fm_4], dim=2)\n",
    "        '''\n",
    "        feat_face = torch.cat([fm_0, fm_1, fm_2, fm_3, fm_4], dim=2)\n",
    "        feat_face = torch.mean(feat_face, dim=1, keepdim=True)  # bs x 1 x channel\n",
    "        feat_face_re = feat_face.repeat(1, feat.shape[1], 1)\n",
    "        '''\n",
    "        return feat\n",
    "\n",
    "class PoseNet9D_Only_R(nn.Module):\n",
    "    def __init__(self, feat_c_R=1280, R_c=4, gcn_n_num=10, gcn_sup_num=7, face_recon_c=6 * 5, obj_c=6, feat_face=768, feat_c_ts=1289, Ts_c=6):\n",
    "        super(PoseNet9D_Only_R, self).__init__()\n",
    "        self.rot_green = Rot_green(feat_c_R, R_c)\n",
    "        self.rot_red = Rot_red(feat_c_R, R_c)\n",
    "        self.face_recon = FaceRecon_feat(gcn_n_num, gcn_sup_num)\n",
    "        # self.ts = Pose_Ts(feat_c_ts, Ts_c)\n",
    "\n",
    "    def forward(self, points):\n",
    "        bs, p_num = points.shape[0], points.shape[1]\n",
    "        feat = self.face_recon(points - points.mean(dim=1, keepdim=True))\n",
    "        #  rotation\n",
    "        green_R_vec = self.rot_green(feat.permute(0, 2, 1))  # b x 4\n",
    "        red_R_vec = self.rot_red(feat.permute(0, 2, 1))   # b x 4\n",
    "        # normalization\n",
    "        p_green_R = green_R_vec[:, 1:] / (torch.norm(green_R_vec[:, 1:], dim=1, keepdim=True) + 1e-6)\n",
    "        p_red_R = red_R_vec[:, 1:] / (torch.norm(red_R_vec[:, 1:], dim=1, keepdim=True) + 1e-6)\n",
    "        # sigmoid for confidence\n",
    "        f_green_R = F.sigmoid(green_R_vec[:, 0])\n",
    "        f_red_R = F.sigmoid(red_R_vec[:, 0])\n",
    "        # translation and size no need\n",
    "        return p_green_R, p_red_R, f_green_R, f_red_R\n",
    "    \n",
    "# loss\n",
    "class fs_net_loss_R(nn.Module):\n",
    "    def __init__(self, loss_type=\"smoothl1\"):\n",
    "        super(fs_net_loss_R, self).__init__()\n",
    "        if loss_type == 'l1':\n",
    "            self.loss_func_t = nn.L1Loss()\n",
    "            self.loss_func_s = nn.L1Loss()\n",
    "            self.loss_func_Rot1 = nn.L1Loss()\n",
    "            self.loss_func_Rot2 = nn.L1Loss()\n",
    "            self.loss_func_r_con = nn.L1Loss()\n",
    "            self.loss_func_Recon = nn.L1Loss()\n",
    "        elif loss_type == 'smoothl1':   # same as MSE\n",
    "            self.loss_func_t = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_s = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Rot1 = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Rot2 = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_r_con = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Recon = nn.SmoothL1Loss(beta=0.3)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, pred_list, gt_list):\n",
    "        loss_list = {}\n",
    "\n",
    "        self.rot_1_w = 1\n",
    "\n",
    "        loss_list[\"Rot1\"] = self.rot_1_w * self.cal_loss_Rot1(pred_list[\"Rot1\"], gt_list[\"Rot1\"])\n",
    "\n",
    "        loss_list[\"Rot2\"] = self.rot_1_w * self.cal_loss_Rot1(pred_list[\"Rot2\"], gt_list[\"Rot2\"])\n",
    "\n",
    "        # loss_list[\"Recon\"] = self.recon_w * self.cal_loss_Recon(pred_list[\"Recon\"], gt_list[\"Recon\"])\n",
    "\n",
    "        # loss_list[\"Tran\"] = self.tran_w * self.cal_loss_Tran(pred_list[\"Tran\"], gt_list[\"Tran\"])\n",
    "    \n",
    "        # loss_list[\"Size\"] = self.size_w * self.cal_loss_Size(pred_list[\"Size\"], gt_list[\"Size\"])\n",
    "\n",
    "        return loss_list\n",
    "\n",
    "    def cal_loss_Rot1(self, pred_v, gt_v):\n",
    "        bs = pred_v.shape[0]\n",
    "        res = torch.zeros([bs], dtype=torch.float32, device=pred_v.device)\n",
    "        for i in range(bs):\n",
    "            pred_v_now = pred_v[i, ...]\n",
    "            gt_v_now = gt_v[i, ...]\n",
    "            res[i] = self.loss_func_Rot1(pred_v_now, gt_v_now)\n",
    "        res = torch.mean(res)\n",
    "        return res\n",
    "\n",
    "    def cal_loss_Rot2(self, pred_v, gt_v, sym):\n",
    "        bs = pred_v.shape[0]\n",
    "        res = 0.0\n",
    "        valid = 0.0\n",
    "        for i in range(bs):\n",
    "            sym_now = sym[i, 0]\n",
    "            if sym_now == 1:\n",
    "                continue\n",
    "            else:\n",
    "                pred_v_now = pred_v[i, ...]\n",
    "                gt_v_now = gt_v[i, ...]\n",
    "                res += self.loss_func_Rot2(pred_v_now, gt_v_now)\n",
    "                valid += 1.0\n",
    "        if valid > 0.0:\n",
    "            res = res / valid\n",
    "        return res\n",
    "\n",
    "    def cal_loss_Recon(self, pred_recon, gt_recon):\n",
    "        return self.loss_func_Recon(pred_recon, gt_recon)\n",
    "\n",
    "    def cal_loss_Tran(self, pred_trans, gt_trans):\n",
    "        return self.loss_func_t(pred_trans, gt_trans)\n",
    "\n",
    "    def cal_loss_Size(self, pred_size, gt_size):\n",
    "        return self.loss_func_s(pred_size, gt_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/16T/zhangran/GAPartNet_re_rendered/train\"\n",
    "test_intra_dir = \"/16T/zhangran/GAPartNet_re_rendered/test_intra\"\n",
    "test_inter_dir = \"/16T/zhangran/GAPartNet_re_rendered/test_inter\"\n",
    "dataset_train = GAPartNetPair(\n",
    "                    Path(root_dir)  / \"pth\",\n",
    "                    Path(root_dir)  / \"meta\",\n",
    "                    shuffle=True,\n",
    "                    max_points=2000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=False, \n",
    "                    group_size=2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    few_shot=False,\n",
    "                    few_shot_num=None,\n",
    "                    # few_shot = True,\n",
    "                    # few_shot_num = 20,\n",
    "                    pos_jitter=0.1,\n",
    "                    with_pose=True,\n",
    "                    color_jitter=0.3,\n",
    "                    flip_prob=0.3,\n",
    "                    rotate_prob=0.3,\n",
    "                )\n",
    "dataloader_train = DataLoader(\n",
    "                    dataset_train,\n",
    "                    batch_size=16,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "dataset_test_intra = GAPartNetPair(\n",
    "                    Path(test_intra_dir)  / \"pth\",\n",
    "                    Path(test_intra_dir)  / \"meta\",\n",
    "                    shuffle=False,\n",
    "                    max_points=2000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=False, \n",
    "                    group_size=2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    few_shot=False,\n",
    "                    few_shot_num=None,\n",
    "                    # few_shot = True,\n",
    "                    # few_shot_num = 20,\n",
    "                    pos_jitter=0.1,\n",
    "                    with_pose=True,\n",
    "                    color_jitter=0.3,\n",
    "                    flip_prob=0.3,\n",
    "                    rotate_prob=0.3,\n",
    "                )\n",
    "dataloader_test_intra = DataLoader(\n",
    "                    dataset_test_intra,\n",
    "                    batch_size=16,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "dataset_test_inter = GAPartNetPair(\n",
    "                    Path(test_inter_dir)  / \"pth\",\n",
    "                    Path(test_inter_dir)  / \"meta\",\n",
    "                    shuffle=False,\n",
    "                    max_points=2000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=False, \n",
    "                    group_size=2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    few_shot=False,\n",
    "                    few_shot_num=None,\n",
    "                    # few_shot = True,\n",
    "                    # few_shot_num = 20,\n",
    "                    pos_jitter=0.1,\n",
    "                    with_pose=True,\n",
    "                    color_jitter=0.3,\n",
    "                    flip_prob=0.3,\n",
    "                    rotate_prob=0.3,\n",
    "                )\n",
    "dataloader_test_inter = DataLoader(\n",
    "                    dataset_test_inter,\n",
    "                    batch_size=16,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_GPV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = PoseNet9D_Only_R()\n",
    "    \n",
    "    def forward(self, pc_list: List[PointCloudPair]):\n",
    "        points1 = torch.cat([pc.pc1.points.unsqueeze(0) for pc in pc_list], dim=0).cuda()  # pc_list is batch size\n",
    "        points2 = torch.cat([pc.pc2.points.unsqueeze(0) for pc in pc_list], dim=0).cuda()\n",
    "        p_green_R1, p_red_R1, f_green_R1, f_red_R1 = self.backbone(points1[:, :, 0:3])\n",
    "        p_green_R2, p_red_R2, f_green_R2, f_red_R2 = self.backbone(points2[:, :, 0:3])\n",
    "        return (p_green_R1, p_red_R1, f_green_R1, f_red_R1), (p_green_R2, p_red_R2, f_green_R2, f_red_R2)\n",
    "\n",
    "def vectors_to_rotation_matrix(green_vector, red_vector):\n",
    "    # green_vector and red_vector are normalized\n",
    "    green_vector = green_vector / torch.norm(green_vector, dim=1, keepdim=True)\n",
    "    red_vector = red_vector / torch.norm(red_vector, dim=1, keepdim=True)\n",
    "    blue_vector = torch.cross(green_vector, red_vector)\n",
    "    \n",
    "    rotation_matrix = torch.stack([red_vector, green_vector, blue_vector], dim=2)\n",
    "    return rotation_matrix\n",
    "\n",
    "def calculate_metrics(predictions, ground_truths):\n",
    "    # Accuracy can be calculated as the mean of correct predictions\n",
    "    accuracy = (predictions.argmax(dim=1) == ground_truths.argmax(dim=1)).float().mean().item()\n",
    "\n",
    "    # Additional metrics using torchmetrics library\n",
    "    precision = torchmetrics.functional.precision(predictions, ground_truths.argmax(dim=1), average='macro', num_classes=predictions.shape[1])\n",
    "    recall = torchmetrics.functional.recall(predictions, ground_truths.argmax(dim=1), average='macro', num_classes=predictions.shape[1])\n",
    "    f1 = torchmetrics.functional.f1_score(predictions, ground_truths.argmax(dim=1), average='macro', num_classes=predictions.shape[1])\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def rotation_matrix_to_euler_angles(Rt):\n",
    "    r = R.from_matrix(Rt.cpu().numpy())\n",
    "    return r.as_euler('xyz', degrees=True)\n",
    "\n",
    "def calculate_pose_metrics(pred_rot_matrices, gt_rot_matrices, pred_translations):\n",
    "    batch_size = pred_rot_matrices.size(0)\n",
    "\n",
    "    rot_errors = []\n",
    "    for i in range(batch_size):\n",
    "        pred_euler = rotation_matrix_to_euler_angles(pred_rot_matrices[i])\n",
    "        gt_euler = rotation_matrix_to_euler_angles(gt_rot_matrices[i])\n",
    "        rot_error = torch.tensor(pred_euler - gt_euler).abs().mean().item()\n",
    "        rot_errors.append(rot_error)\n",
    "    mean_rot_error = sum(rot_errors) / batch_size\n",
    "    return mean_rot_error\n",
    "\n",
    "# Helper function to extract ground truth rotation vectors from the batch of PointCloudPairs\n",
    "def ground_truth_rotations(rot_list: List[torch.Tensor]) -> np.ndarray:\n",
    "    rotations = []\n",
    "    for rot in rot_list:\n",
    "        # Assuming the rotations are stored as 3x3 matrices in pc_pair.rot_1 and pc_pair.rot_2\n",
    "        rotation_matrix = np.array(rot.cpu())  # Example using rot_1, adjust as needed\n",
    "        rotations.append(rotation_matrix)\n",
    "    return torch.tensor(np.stack(rotations))\n",
    "\n",
    "def train(model: test_GPV, dataloader_train, dataloader_test_inter, dataloader_test_intra, lr, num_epochs, log_dir):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = fs_net_loss_R()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    log_dir = log_dir + \"/\" + str(datetime.today())\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    print(\"_________________________train_epoch___________________________\")\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        if epoch == 0:\n",
    "            # first test epoch\n",
    "            print(\"______________________first_test_epoch_________________________\")\n",
    "            torch.save(model.state_dict(), log_dir+r'/'+f\"GPV_[{epoch+1}|{num_epochs}].pth\")\n",
    "            test_metrics(model, dataloader_test_inter, device, writer, epoch, 'test_inter')\n",
    "            test_metrics(model, dataloader_test_intra, device, writer, epoch, 'test_intra')\n",
    "        for batch_idx, batch in enumerate(dataloader_train):\n",
    "            pc_pairs = [pair.to(device) for pair in batch]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            (p_green_R1, p_red_R1, f_green_R1, f_red_R1), (p_green_R2, p_red_R2, f_green_R2, f_red_R2) = model(pc_pairs)\n",
    "            \n",
    "            # Assuming we have ground truth rotations\n",
    "            R_green_gt1, R_red_gt1 = get_gt_v(ground_truth_rotations([pc.rot_1 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            R_green_gt2, R_red_gt2 = get_gt_v(ground_truth_rotations([pc.rot_2 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            \n",
    "            pred_list1 = {\n",
    "                \"Rot1\": p_green_R1,\n",
    "                \"Rot2\": p_red_R1,\n",
    "            }\n",
    "            gt_list1 = {\n",
    "                \"Rot1\": R_green_gt1.cuda(),\n",
    "                \"Rot2\": R_red_gt1.cuda(),\n",
    "            }\n",
    "            \n",
    "            pred_list2 = {\n",
    "                \"Rot1\": p_green_R2,\n",
    "                \"Rot2\": p_red_R2,\n",
    "            }\n",
    "            gt_list2 = {\n",
    "                \"Rot1\": R_green_gt2.cuda(),\n",
    "                \"Rot2\": R_red_gt2.cuda(),\n",
    "            }\n",
    "\n",
    "            loss_dict1 = criterion(pred_list1, gt_list1)\n",
    "            loss_dict2 = criterion(pred_list2, gt_list2)\n",
    "            loss = (loss_dict1['Rot1'] + loss_dict1['Rot2'] + loss_dict2['Rot1'] + loss_dict2['Rot2']) / 2.0\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # 每10个batch记录一次loss\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                writer.add_scalar('train/loss', loss.item(), global_step)\n",
    "                print(f\"Epoch:[{epoch + 1}|{num_epochs}],Batch:[{(batch_idx + 1)}|{len(dataloader_train)}],Loss:[{loss.item():.4f}]\")\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader_train)\n",
    "        print(f\"Epoch [{epoch+1}|{num_epochs}],Loss:{avg_loss:.4f}\")\n",
    "        writer.add_scalar('train/avg_loss', avg_loss, epoch)\n",
    "\n",
    "        # 每5个epoch跑一次测试集\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), log_dir+r'/'+f\"GPV_[{epoch+1}|{num_epochs}].pth\")\n",
    "            test_metrics(model, dataloader_test_inter, device, writer, epoch, 'test_inter')\n",
    "            test_metrics(model, dataloader_test_intra, device, writer, epoch, 'test_intra')\n",
    "\n",
    "\n",
    "def test_metrics(model, dataloader, device, writer, epoch, phase):\n",
    "    print(\"______________________\" + phase + \"_______________________\")\n",
    "    model.eval()\n",
    "    all_pred_rot_matrices = []\n",
    "    all_gt_rot_matrices = []\n",
    "    all_pred_translations = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            pc_pairs = [pair.to(device) for pair in batch]\n",
    "            (p_green_R1, p_red_R1, f_green_R1, f_red_R1), (p_green_R2, p_red_R2, f_green_R2, f_red_R2) = model(pc_pairs)\n",
    "            \n",
    "            # Assuming we have ground truth rotations\n",
    "            R_green_gt1, R_red_gt1 = get_gt_v(ground_truth_rotations([pc.rot_1 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            R_green_gt2, R_red_gt2 = get_gt_v(ground_truth_rotations([pc.rot_2 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            \n",
    "            # Convert predicted vectors and ground truth vectors back to rotation matrices\n",
    "            pred_rot_matrices1 = vectors_to_rotation_matrix(p_green_R1, p_red_R1)\n",
    "            pred_rot_matrices2 = vectors_to_rotation_matrix(p_green_R2, p_red_R2)\n",
    "            gt_rot_matrices1 = vectors_to_rotation_matrix(R_green_gt1, R_red_gt1)\n",
    "            gt_rot_matrices2 = vectors_to_rotation_matrix(R_green_gt2, R_red_gt2)\n",
    "            \n",
    "            # Store predictions and ground truths for metrics calculation\n",
    "            all_pred_rot_matrices.append(pred_rot_matrices1.cpu())\n",
    "            all_pred_rot_matrices.append(pred_rot_matrices2.cpu())\n",
    "            all_gt_rot_matrices.append(gt_rot_matrices1.cpu())\n",
    "            all_gt_rot_matrices.append(gt_rot_matrices2.cpu())\n",
    "            all_pred_translations.append(f_green_R1.cpu())\n",
    "            all_pred_translations.append(f_green_R2.cpu())\n",
    "    \n",
    "    all_pred_rot_matrices = torch.cat(all_pred_rot_matrices, dim=0)\n",
    "    all_gt_rot_matrices = torch.cat(all_gt_rot_matrices, dim=0)\n",
    "    all_pred_translations = torch.cat(all_pred_translations, dim=0)\n",
    "\n",
    "    mean_rot_error = calculate_pose_metrics(\n",
    "        all_pred_rot_matrices, all_gt_rot_matrices, all_pred_translations\n",
    "    )\n",
    "    writer.add_scalar(f'{phase}/mean_rot_error', mean_rot_error, epoch)\n",
    "    print(f\"{phase} - Epoch [{epoch+1}]: Mean Rotation Error: {mean_rot_error:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = test_GPV().cuda()\n",
    "model.load_state_dict(torch.load('./log_dir/GPV_test/2024-05-22 01:41:18.391449/GPV_[40|40].pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.3428044e-01 -1.8115395e-01  7.5157940e-01]\n",
      " [-7.7310312e-01 -1.4862490e-01  6.1662173e-01]\n",
      " [-2.9802322e-08 -9.7215950e-01 -2.3432052e-01]]\n",
      "tensor([[[ 6.3428e-01, -1.8115e-01, -7.5158e-01],\n",
      "         [-7.7310e-01, -1.4862e-01, -6.1662e-01],\n",
      "         [-2.9802e-08, -9.7216e-01,  2.3432e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# get first axis and the other axis. \n",
    "rotation_gt = np.array([\n",
    "    0.6342804431915283,\n",
    "    -0.18115395307540894,\n",
    "    0.7515794038772583,\n",
    "    -0.7731031179428101,\n",
    "    -0.14862489700317383,\n",
    "    0.616621732711792,\n",
    "    -2.9802322387695312e-08,\n",
    "    -0.9721595048904419,\n",
    "    -0.2343205213546753\n",
    "], dtype=np.float32).reshape(3,3)\n",
    "print(rotation_gt)\n",
    "R_green, R_red = get_gt_v(torch.tensor(rotation_gt).unsqueeze(0))\n",
    "rotation = vectors_to_rotation_matrix(R_green, R_red)\n",
    "print(rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16447\n",
      "883\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "import visu\n",
    "for dataset in [dataset_train, dataset_test_inter, dataset_test_intra]:\n",
    "    model.eval()\n",
    "    i = random.randint(0, len(dataset))\n",
    "    print(i)\n",
    "    inputs = dataset[i]\n",
    "    dir_name = {\n",
    "        dataset_train: root_dir,\n",
    "        dataset_test_inter: test_inter_dir,\n",
    "        dataset_test_intra: test_intra_dir\n",
    "    }\n",
    "    log_name = {\n",
    "        dataset_train: \"train\",\n",
    "        dataset_test_inter: \"inter\",\n",
    "        dataset_test_intra: \"intra\"\n",
    "    }\n",
    "    name_1 = dataset.group_files[i][0].split('/')[-1].split('.')[0]\n",
    "    name_2 = dataset.group_files[i][1].split('/')[-1].split('.')[0]\n",
    "    with torch.no_grad():\n",
    "        (p_green_R1, p_red_R1, f_green_R1, f_red_R1), (p_green_R2, p_red_R2, f_green_R2, f_red_R2) = model([inputs])\n",
    "    rot_1_pred = vectors_to_rotation_matrix(p_green_R1, p_red_R1)\n",
    "    rot_2_pred = vectors_to_rotation_matrix(p_green_R2, p_red_R2)\n",
    "    visu.visualize_gapartnet(f\"./log_dir/GPV_test/visu/{log_name[dataset]}\", dir_name[dataset], None, ['pc', 'world_gt', 'world_pred'], name_1, rot_pred = rot_1_pred.detach().squeeze(0).cpu(), five=False)\n",
    "    visu.visualize_gapartnet(f\"./log_dir/GPV_test/visu/{log_name[dataset]}\", dir_name[dataset], None, ['pc', 'world_gt', 'world_pred'], name_2, rot_pred = rot_2_pred.detach().squeeze(0).cpu(), five=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
