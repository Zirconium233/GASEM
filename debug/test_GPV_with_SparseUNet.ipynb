{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from network.gap_layers import *\n",
    "from datasets.datasets_pair import *\n",
    "import functools\n",
    "from network.sym_v1 import *\n",
    "from loss.utils import *\n",
    "from network.utils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_Sparse_UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sparseunet = SparseUNet.build(6, [16, 32, 48, 64, 80, 96, 112], 2, functools.partial(nn.BatchNorm1d, eps=1e-4, momentum=0.1))\n",
    "        self.rot_green_head = nn.Linear(16, 3)\n",
    "        self.rot_red_head = nn.Linear(16, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, pc_pairs: List[PointCloudPair]):\n",
    "        pc1s = [pc_pair.pc1 for pc_pair in pc_pairs]\n",
    "        pc2s = [pc_pair.pc2 for pc_pair in pc_pairs]\n",
    "        bs = len(pc_pairs)\n",
    "        pc_batch_1: PointCloudBatch = PointCloud.collate(pc1s)\n",
    "        pc_batch_2: PointCloudBatch = PointCloud.collate(pc2s)\n",
    "        \n",
    "        voxel_tensor_1 = pc_batch_1.voxel_tensor\n",
    "        pc_voxel_id_1 = pc_batch_1.pc_voxel_id\n",
    "        voxel_features = self.sparseunet(voxel_tensor_1)\n",
    "        pc_feature_1 = voxel_features.features[pc_voxel_id_1]\n",
    "\n",
    "        voxel_tensor_2 = pc_batch_2.voxel_tensor\n",
    "        pc_voxel_id_2 = pc_batch_2.pc_voxel_id\n",
    "        voxel_features = self.sparseunet(voxel_tensor_2)\n",
    "        pc_feature_2 = voxel_features.features[pc_voxel_id_2]\n",
    "\n",
    "        pc_feature_1 = pc_feature_1.view(bs, -1, 16) # bs,n,16\n",
    "        pc_feature_2 = pc_feature_2.view(bs, -1, 16)\n",
    "\n",
    "        rot_green_1 = self.rot_green_head(pc_feature_1).mean(dim=1).view(bs, 3) # bs,n,3\n",
    "        rot_green_2 = self.rot_green_head(pc_feature_2).mean(dim=1).view(bs, 3)\n",
    "\n",
    "        rot_red_1 = self.rot_red_head(pc_feature_1).mean(dim=1).view(bs, 3)\n",
    "        rot_red_2 = self.rot_red_head(pc_feature_2).mean(dim=1).view(bs, 3) # bs,3\n",
    "        \n",
    "        return (rot_green_1, rot_green_2), (rot_red_1, rot_red_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "class fs_net_loss_R(nn.Module):\n",
    "    def __init__(self, loss_type=\"smoothl1\"):\n",
    "        super(fs_net_loss_R, self).__init__()\n",
    "        if loss_type == 'l1':\n",
    "            self.loss_func_t = nn.L1Loss()\n",
    "            self.loss_func_s = nn.L1Loss()\n",
    "            self.loss_func_Rot1 = nn.L1Loss()\n",
    "            self.loss_func_Rot2 = nn.L1Loss()\n",
    "            self.loss_func_r_con = nn.L1Loss()\n",
    "            self.loss_func_Recon = nn.L1Loss()\n",
    "        elif loss_type == 'smoothl1':   # same as MSE\n",
    "            self.loss_func_t = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_s = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Rot1 = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Rot2 = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_r_con = nn.SmoothL1Loss(beta=0.5)\n",
    "            self.loss_func_Recon = nn.SmoothL1Loss(beta=0.3)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, pred_list, gt_list, sym):\n",
    "        loss_list = {}\n",
    "\n",
    "        self.rot_1_w = 1\n",
    "\n",
    "        loss_list[\"Rot1\"] = self.rot_1_w * self.cal_loss_Rot1(pred_list[\"Rot1\"], gt_list[\"Rot1\"])\n",
    "\n",
    "        loss_list[\"Rot2\"] = self.rot_1_w * self.cal_loss_Rot2(pred_list[\"Rot2\"], gt_list[\"Rot2\"], sym)\n",
    "\n",
    "        # loss_list[\"Recon\"] = self.recon_w * self.cal_loss_Recon(pred_list[\"Recon\"], gt_list[\"Recon\"])\n",
    "\n",
    "        # loss_list[\"Tran\"] = self.tran_w * self.cal_loss_Tran(pred_list[\"Tran\"], gt_list[\"Tran\"])\n",
    "    \n",
    "        # loss_list[\"Size\"] = self.size_w * self.cal_loss_Size(pred_list[\"Size\"], gt_list[\"Size\"])\n",
    "\n",
    "        return loss_list\n",
    "\n",
    "    def cal_loss_Rot1(self, pred_v, gt_v):\n",
    "        bs = pred_v.shape[0]\n",
    "        res = torch.zeros([bs], dtype=torch.float32, device=pred_v.device)\n",
    "        for i in range(bs):\n",
    "            pred_v_now = pred_v[i, ...]\n",
    "            gt_v_now = gt_v[i, ...]\n",
    "            res[i] = self.loss_func_Rot1(pred_v_now, gt_v_now)\n",
    "        res = torch.mean(res)\n",
    "        return res\n",
    "\n",
    "    def cal_loss_Rot2(self, pred_v, gt_v, sym):\n",
    "        bs = pred_v.shape[0]\n",
    "        res = 0.0\n",
    "        valid = 0.0\n",
    "        for i in range(bs):\n",
    "            sym_now = sym[i, 0]\n",
    "            if sym_now == 1:\n",
    "                continue\n",
    "            else:\n",
    "                pred_v_now = pred_v[i, ...]\n",
    "                gt_v_now = gt_v[i, ...]\n",
    "                res += self.loss_func_Rot2(pred_v_now, gt_v_now)\n",
    "                valid += 1.0\n",
    "        if valid > 0.0:\n",
    "            res = res / valid\n",
    "        return res\n",
    "\n",
    "    def cal_loss_Recon(self, pred_recon, gt_recon):\n",
    "        return self.loss_func_Recon(pred_recon, gt_recon)\n",
    "\n",
    "    def cal_loss_Tran(self, pred_trans, gt_trans):\n",
    "        return self.loss_func_t(pred_trans, gt_trans)\n",
    "\n",
    "    def cal_loss_Size(self, pred_size, gt_size):\n",
    "        return self.loss_func_s(pred_size, gt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/16T/zhangran/GAPartNet_re_rendered/train\"\n",
    "test_intra_dir = \"/16T/zhangran/GAPartNet_re_rendered/test_intra\"\n",
    "test_inter_dir = \"/16T/zhangran/GAPartNet_re_rendered/test_inter\"\n",
    "dataset_train = GAPartNetPair(\n",
    "                    Path(root_dir)  / \"pth\",\n",
    "                    Path(root_dir)  / \"meta\",\n",
    "                    shuffle=True,\n",
    "                    max_points=2000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=True, \n",
    "                    group_size=2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    # few_shot=False,\n",
    "                    # few_shot_num=None,\n",
    "                    few_shot = True,\n",
    "                    few_shot_num = 20,\n",
    "                    pos_jitter=0.1,\n",
    "                    with_pose=True,\n",
    "                    color_jitter=0.3,\n",
    "                    flip_prob=0.3,\n",
    "                    rotate_prob=0.3,\n",
    "                )\n",
    "dataloader_train = DataLoader(\n",
    "                    dataset_train,\n",
    "                    batch_size=16,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "dataset_test_intra = GAPartNetPair(\n",
    "                    Path(test_intra_dir)  / \"pth\",\n",
    "                    Path(test_intra_dir)  / \"meta\",\n",
    "                    shuffle=False,\n",
    "                    max_points=2000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=True, \n",
    "                    group_size=2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    # few_shot=False,\n",
    "                    # few_shot_num=None,\n",
    "                    few_shot = True,\n",
    "                    few_shot_num = 20,\n",
    "                    pos_jitter=0.1,\n",
    "                    with_pose=True,\n",
    "                    color_jitter=0.3,\n",
    "                    flip_prob=0.3,\n",
    "                    rotate_prob=0.3,\n",
    "                )\n",
    "dataloader_test_intra = DataLoader(\n",
    "                    dataset_test_intra,\n",
    "                    batch_size=16,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )\n",
    "dataset_test_inter = GAPartNetPair(\n",
    "                    Path(test_inter_dir)  / \"pth\",\n",
    "                    Path(test_inter_dir)  / \"meta\",\n",
    "                    shuffle=False,\n",
    "                    max_points=2000,\n",
    "                    augmentation=True,\n",
    "                    voxelization=True, \n",
    "                    group_size=2,\n",
    "                    voxel_size=[0.01,0.01,0.01],\n",
    "                    # few_shot=False,\n",
    "                    # few_shot_num=None,\n",
    "                    few_shot = True,\n",
    "                    few_shot_num = 20,\n",
    "                    pos_jitter=0.1,\n",
    "                    with_pose=True,\n",
    "                    color_jitter=0.3,\n",
    "                    flip_prob=0.3,\n",
    "                    rotate_prob=0.3,\n",
    "                )\n",
    "dataloader_test_inter = DataLoader(\n",
    "                    dataset_test_inter,\n",
    "                    batch_size=16,\n",
    "                    shuffle=False,\n",
    "                    num_workers=8,\n",
    "                    collate_fn=data_utils.trivial_batch_collator,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract ground truth rotation vectors from the batch of PointCloudPairs\n",
    "def ground_truth_rotations(rot_list: List[torch.Tensor]) -> np.ndarray:\n",
    "    rotations = []\n",
    "    for rot in rot_list:\n",
    "        # Assuming the rotations are stored as 3x3 matrices in pc_pair.rot_1 and pc_pair.rot_2\n",
    "        rotation_matrix = np.array(rot.cpu())  # Example using rot_1, adjust as needed\n",
    "        rotations.append(rotation_matrix)\n",
    "    return torch.tensor(np.stack(rotations))\n",
    "\n",
    "def train(model: nn.Module, \n",
    "          dataloader_train: DataLoader, \n",
    "          dataloader_test_inter: DataLoader, \n",
    "          dataloader_test_intra: DataLoader, \n",
    "          lr: int = 0.001, \n",
    "          num_epochs: int=100, \n",
    "          log_dir: str=None, \n",
    "          device: torch.device=None):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = fs_net_loss_R()\n",
    "    if not device:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    assert log_dir is not None, \"No Log Dir\"\n",
    "    log_dir = log_dir + \"/\" + str(datetime.today())\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    print(\"_________________________train_epoch___________________________\")\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        if epoch == 0:\n",
    "            # first test epoch\n",
    "            print(\"______________________first_test_epoch_________________________\")\n",
    "            torch.save(model.state_dict(), log_dir+r'/'+f\"GPV_[{epoch+1}|{num_epochs}].pth\")\n",
    "            test_metrics(model, dataloader_test_inter, device, writer, epoch, 'test_inter')\n",
    "            test_metrics(model, dataloader_test_intra, device, writer, epoch, 'test_intra')\n",
    "        for batch_idx, batch in enumerate(dataloader_train):\n",
    "            pc_pairs = [pair.to(device) for pair in batch]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            (p_green_R1, p_red_R1), (p_green_R2, p_red_R2) = model(pc_pairs)\n",
    "            \n",
    "            # Assuming we have ground truth rotations\n",
    "            R_green_gt1, R_red_gt1 = get_gt_v(ground_truth_rotations([pc.rot_1 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            R_green_gt2, R_red_gt2 = get_gt_v(ground_truth_rotations([pc.rot_2 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            \n",
    "            pred_list1 = {\n",
    "                \"Rot1\": p_green_R1,\n",
    "                \"Rot2\": p_red_R1,\n",
    "            }\n",
    "            gt_list1 = {\n",
    "                \"Rot1\": R_green_gt1.cuda(),\n",
    "                \"Rot2\": R_red_gt1.cuda(),\n",
    "            }\n",
    "            \n",
    "            pred_list2 = {\n",
    "                \"Rot1\": p_green_R2,\n",
    "                \"Rot2\": p_red_R2,\n",
    "            }\n",
    "            gt_list2 = {\n",
    "                \"Rot1\": R_green_gt2.cuda(),\n",
    "                \"Rot2\": R_red_gt2.cuda(),\n",
    "            }\n",
    "\n",
    "            sym1, sym2 = get_sym_from_input(pc_pairs)\n",
    "\n",
    "            loss_dict1 = criterion(pred_list1, gt_list1, sym1)\n",
    "            loss_dict2 = criterion(pred_list2, gt_list2, sym2)\n",
    "            loss = (loss_dict1['Rot1'] + loss_dict1['Rot2'] + loss_dict2['Rot1'] + loss_dict2['Rot2']) / 2.0\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # 每10个batch记录一次loss\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                writer.add_scalar('train/loss', loss.item(), global_step)\n",
    "                print(f\"Epoch:[{epoch + 1}|{num_epochs}],Batch:[{(batch_idx + 1)}|{len(dataloader_train)}],Loss:[{loss.item():.4f}]\")\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader_train)\n",
    "        print(f\"Epoch [{epoch+1}|{num_epochs}],Loss:{avg_loss:.4f}\")\n",
    "        writer.add_scalar('train/avg_loss', avg_loss, epoch)\n",
    "\n",
    "        # 每5个epoch跑一次测试集\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), log_dir+r'/'+f\"GPV_[{epoch+1}|{num_epochs}].pth\")\n",
    "            test_metrics(model, dataloader_test_inter, device, writer, epoch, 'test_inter')\n",
    "            test_metrics(model, dataloader_test_intra, device, writer, epoch, 'test_intra')\n",
    "\n",
    "\n",
    "def test_metrics(model, dataloader, device, writer, epoch, phase):\n",
    "    print(\"______________________\" + phase + \"_______________________\")\n",
    "    model.eval()\n",
    "    all_pred_rot_matrices = []\n",
    "    all_gt_rot_matrices = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            pc_pairs = [pair.to(device) for pair in batch]\n",
    "            (p_green_R1, p_red_R1), (p_green_R2, p_red_R2) = model(pc_pairs)\n",
    "            \n",
    "            # Assuming we have ground truth rotations\n",
    "            R_green_gt1, R_red_gt1 = get_gt_v(ground_truth_rotations([pc.rot_1 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            R_green_gt2, R_red_gt2 = get_gt_v(ground_truth_rotations([pc.rot_2 for pc in pc_pairs]))  # Function to get ground truth rotation vectors\n",
    "            \n",
    "            # Convert predicted vectors and ground truth vectors back to rotation matrices\n",
    "            pred_rot_matrices1 = vectors_to_rotation_matrix(p_green_R1, p_red_R1)\n",
    "            pred_rot_matrices2 = vectors_to_rotation_matrix(p_green_R2, p_red_R2)\n",
    "            gt_rot_matrices1 = vectors_to_rotation_matrix(R_green_gt1, R_red_gt1)\n",
    "            gt_rot_matrices2 = vectors_to_rotation_matrix(R_green_gt2, R_red_gt2)\n",
    "            \n",
    "            # Store predictions and ground truths for metrics calculation\n",
    "            all_pred_rot_matrices.append(pred_rot_matrices1.cpu())\n",
    "            all_pred_rot_matrices.append(pred_rot_matrices2.cpu())\n",
    "            all_gt_rot_matrices.append(gt_rot_matrices1.cpu())\n",
    "            all_gt_rot_matrices.append(gt_rot_matrices2.cpu())\n",
    "    \n",
    "    all_pred_rot_matrices = torch.cat(all_pred_rot_matrices, dim=0)\n",
    "    all_gt_rot_matrices = torch.cat(all_gt_rot_matrices, dim=0)\n",
    "\n",
    "    mean_rot_error = calculate_pose_metrics(\n",
    "        all_pred_rot_matrices, all_gt_rot_matrices\n",
    "    )\n",
    "    writer.add_scalar(f'{phase}/mean_rot_error', mean_rot_error, epoch)\n",
    "    print(f\"{phase} - Epoch [{epoch+1}]: Mean Rotation Error: {mean_rot_error:.4f}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________train_epoch___________________________\n",
      "______________________first_test_epoch_________________________\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [1]: Mean Rotation Error: 78.6786\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [1]: Mean Rotation Error: 83.4702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1|40],Loss:0.9508\n",
      "Epoch [2|40],Loss:0.8280\n",
      "Epoch [3|40],Loss:0.7778\n",
      "Epoch [4|40],Loss:0.7134\n",
      "Epoch [5|40],Loss:0.6653\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [5]: Mean Rotation Error: 92.5140\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [5]: Mean Rotation Error: 109.2145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6|40],Loss:0.6408\n",
      "Epoch [7|40],Loss:0.6230\n",
      "Epoch [8|40],Loss:0.5990\n",
      "Epoch [9|40],Loss:0.5873\n",
      "Epoch [10|40],Loss:0.5704\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [10]: Mean Rotation Error: 94.6411\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [10]: Mean Rotation Error: 103.7276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11|40],Loss:0.5625\n",
      "Epoch [12|40],Loss:0.5419\n",
      "Epoch [13|40],Loss:0.5286\n",
      "Epoch [14|40],Loss:0.5204\n",
      "Epoch [15|40],Loss:0.5069\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [15]: Mean Rotation Error: 91.3609\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [15]: Mean Rotation Error: 96.6759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16|40],Loss:0.5169\n",
      "Epoch [17|40],Loss:0.4933\n",
      "Epoch [18|40],Loss:0.4894\n",
      "Epoch [19|40],Loss:0.4904\n",
      "Epoch [20|40],Loss:0.4692\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [20]: Mean Rotation Error: 85.5564\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [20]: Mean Rotation Error: 94.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21|40],Loss:0.4724\n",
      "Epoch [22|40],Loss:0.4638\n",
      "Epoch [23|40],Loss:0.4679\n",
      "Epoch [24|40],Loss:0.4545\n",
      "Epoch [25|40],Loss:0.4627\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [25]: Mean Rotation Error: 81.9781\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [25]: Mean Rotation Error: 93.1520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26|40],Loss:0.4333\n",
      "Epoch [27|40],Loss:0.4401\n",
      "Epoch [28|40],Loss:0.4318\n",
      "Epoch [29|40],Loss:0.4187\n",
      "Epoch [30|40],Loss:0.4077\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [30]: Mean Rotation Error: 87.9669\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [30]: Mean Rotation Error: 93.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31|40],Loss:0.4105\n",
      "Epoch [32|40],Loss:0.4086\n",
      "Epoch [33|40],Loss:0.4092\n",
      "Epoch [34|40],Loss:0.4024\n",
      "Epoch [35|40],Loss:0.3938\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [35]: Mean Rotation Error: 93.5850\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [35]: Mean Rotation Error: 90.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36|40],Loss:0.4145\n",
      "Epoch [37|40],Loss:0.4048\n",
      "Epoch [38|40],Loss:0.3967\n",
      "Epoch [39|40],Loss:0.3986\n",
      "Epoch [40|40],Loss:0.3899\n",
      "______________________test_inter_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_inter - Epoch [40]: Mean Rotation Error: 89.2675\n",
      "______________________test_intra_______________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_intra - Epoch [40]: Mean Rotation Error: 73.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = test_Sparse_UNet()\n",
    "train(model, dataloader_train, dataloader_test_inter, dataloader_test_intra, 0.001, 40, \"./log_dir/SparseUNet_test_sym_v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
