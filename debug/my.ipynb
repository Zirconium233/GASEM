{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import functools\n",
    "import spconv.pytorch as spconv\n",
    "from typing import List, Tuple, Union, Optional, Dict, Any\n",
    "from torch.autograd import Variable\n",
    "from dataclasses import dataclass, fields\n",
    "import numpy as np\n",
    "import copy\n",
    "from epic_ops.reduce import segmented_reduce\n",
    "from epic_ops.voxelize import voxelize\n",
    "from epic_ops.ball_query import ball_query\n",
    "from epic_ops.ccl import connected_components_labeling\n",
    "from epic_ops.nms import nms\n",
    "from epic_ops.reduce import segmented_maxpool\n",
    "from gapartnet.misc.info import get_symmetry_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data class\n",
    "@dataclass\n",
    "class Segmentation:\n",
    "    batch_size: int\n",
    "\n",
    "    sem_preds: torch.Tensor\n",
    "    sem_labels: Optional[torch.Tensor] = None\n",
    "    all_accu: Optional[torch.Tensor] = None\n",
    "    pixel_accu: Optional[float] = None\n",
    "\n",
    "@dataclass\n",
    "class Instances:\n",
    "    valid_mask: Optional[torch.Tensor] = None\n",
    "    sorted_indices: Optional[torch.Tensor] = None\n",
    "    pt_xyz: Optional[torch.Tensor] = None\n",
    "\n",
    "    batch_indices: Optional[torch.Tensor] = None\n",
    "    proposal_offsets: Optional[torch.Tensor] = None\n",
    "    proposal_indices: Optional[torch.Tensor] = None\n",
    "    num_points_per_proposal: Optional[torch.Tensor] = None\n",
    "\n",
    "    sem_preds: Optional[torch.Tensor] = None\n",
    "    pt_sem_classes: Optional[torch.Tensor] = None\n",
    "    score_preds: Optional[torch.Tensor] = None\n",
    "    npcs_preds: Optional[torch.Tensor] = None\n",
    "\n",
    "    sem_labels: Optional[torch.Tensor] = None\n",
    "    instance_labels: Optional[torch.Tensor] = None\n",
    "    instance_sem_labels: Optional[torch.Tensor] = None\n",
    "    num_points_per_instance: Optional[torch.Tensor] = None\n",
    "    gt_npcs: Optional[torch.Tensor] = None\n",
    "\n",
    "    npcs_valid_mask: Optional[torch.Tensor] = None\n",
    "\n",
    "    ious: Optional[torch.Tensor] = None\n",
    "\n",
    "    cls_preds: Optional[torch.Tensor] = None\n",
    "    cls_labels: Optional[torch.Tensor] = None\n",
    "    \n",
    "    name: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    xyz: torch.Tensor\n",
    "    rgb: torch.Tensor\n",
    "    sem_preds: torch.Tensor\n",
    "    ins_preds: torch.Tensor\n",
    "    npcs_preds: torch.Tensor\n",
    "\n",
    "@dataclass\n",
    "class PointCloudBatch:\n",
    "    # basic\n",
    "    pc_ids: List[str]\n",
    "    points: torch.Tensor\n",
    "    batch_indices: torch.Tensor\n",
    "    batch_size: int\n",
    "    device: str = None # type: ignore\n",
    "    \n",
    "    # voxel\n",
    "    voxel_tensor: any = None, # type: ignore\n",
    "    pc_voxel_id: any = None # type: ignore\n",
    "\n",
    "    # semantic\n",
    "    sem_labels: torch.Tensor = None # type: ignore\n",
    "    obj_cls_labels = None\n",
    "    \n",
    "    # instance\n",
    "    instance_labels: Optional[torch.Tensor] = None\n",
    "    num_instances: Optional[List[int]] = None\n",
    "    instance_regions: Optional[torch.Tensor] = None\n",
    "    num_points_per_instance: Optional[torch.Tensor] = None\n",
    "    instance_sem_labels: Optional[torch.Tensor] = None\n",
    "    \n",
    "    #npcs\n",
    "    gt_npcs: Optional[Union[torch.Tensor, np.ndarray]] = None\n",
    "\n",
    "@dataclass\n",
    "class PointCloud:\n",
    "    pc_id: str\n",
    "\n",
    "    points: Union[torch.Tensor, np.ndarray]\n",
    "    \n",
    "    obj_cat: int = -1\n",
    "\n",
    "    sem_labels: Optional[Union[torch.Tensor, np.ndarray]] = None\n",
    "    instance_labels: Optional[Union[torch.Tensor, np.ndarray]] = None\n",
    "\n",
    "    gt_npcs: Optional[Union[torch.Tensor, np.ndarray]] = None\n",
    "\n",
    "    # instance number\n",
    "    num_instances: Optional[int] = None \n",
    "    \n",
    "    # for points in an instance: 0-3: mean_xyz; 3-6: max_xyz; 6-9: min_xyz\n",
    "    instance_regions: Optional[Union[torch.Tensor, np.ndarray]] = None\n",
    "    \n",
    "    # instance points number\n",
    "    num_points_per_instance: Optional[Union[torch.Tensor, np.ndarray]] = None\n",
    "    \n",
    "    # instance semantic label\n",
    "    instance_sem_labels: Optional[torch.Tensor] = None\n",
    "\n",
    "    voxel_features: Optional[torch.Tensor] = None\n",
    "    voxel_coords: Optional[torch.Tensor] = None\n",
    "    voxel_coords_range: Optional[List[int]] = None\n",
    "    pc_voxel_id: Optional[torch.Tensor] = None\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            field.name: getattr(self, field.name)\n",
    "            for field in fields(self)\n",
    "        }\n",
    "\n",
    "    def to_tensor(self) -> \"PointCloud\":\n",
    "        return PointCloud(**{\n",
    "            k: torch.from_numpy(v) if isinstance(v, np.ndarray) else v\n",
    "            for k, v in self.to_dict().items()\n",
    "        }) # type: ignore\n",
    "\n",
    "    def to(self, device: torch.device) -> \"PointCloud\":\n",
    "        return PointCloud(**{\n",
    "            k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "            for k, v in self.to_dict().items()\n",
    "        }) # type: ignore\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(point_clouds: List[\"PointCloud\"]) -> PointCloudBatch: # 这里合并体素化的PointCloud，创建稀疏张量\n",
    "        \"\"\"\n",
    "        将一个点云列表转换为一个 PointCloudBatch 对象。\n",
    "\n",
    "        Args:\n",
    "            point_clouds (List[PointCloud]): 包含多个点云的列表。\n",
    "\n",
    "        Returns:\n",
    "            PointCloudBatch: 一个包含所有点云信息的 PointCloudBatch 对象。\n",
    "        \"\"\"\n",
    "        batch_size = len(point_clouds)  # 获取点云列表的长度，即批次大小\n",
    "        device = point_clouds[0].points.device  # 获取点云的设备类型\n",
    "\n",
    "        # 提取每个点云的id、对象类别标签、点数等信息\n",
    "        pc_ids = [pc.pc_id for pc in point_clouds]\n",
    "        cls_labels = torch.tensor([pc.obj_cat for pc in point_clouds])\n",
    "        num_points = [pc.points.shape[0] for pc in point_clouds]\n",
    "\n",
    "        # 合并所有点云的点坐标\n",
    "        points = torch.cat([pc.points for pc in point_clouds], dim=0)\n",
    "        \n",
    "        # 生成每个点对应的批次索引\n",
    "        batch_indices = torch.cat([\n",
    "            torch.full((pc.points.shape[0],), i, dtype=torch.int32, device=device)\n",
    "            for i, pc in enumerate(point_clouds)\n",
    "        ], dim=0)\n",
    "\n",
    "        # 合并所有点云的语义标签（如果有）\n",
    "        if point_clouds[0].sem_labels is not None:\n",
    "            sem_labels = torch.cat([pc.sem_labels for pc in point_clouds], dim=0)\n",
    "        else:\n",
    "            sem_labels = None\n",
    "\n",
    "        # 合并所有点云的实例标签（如果有）\n",
    "        if point_clouds[0].instance_labels is not None:\n",
    "            instance_labels = torch.cat([pc.instance_labels for pc in point_clouds], dim=0)\n",
    "        else:\n",
    "            instance_labels = None\n",
    "\n",
    "        # 合并所有点云的gt_npcs（如果有）\n",
    "        if point_clouds[0].gt_npcs is not None:\n",
    "            gt_npcs = torch.cat([pc.gt_npcs for pc in point_clouds], dim=0)\n",
    "        else:\n",
    "            gt_npcs = None\n",
    "\n",
    "        # 处理每个点云的实例信息\n",
    "        if point_clouds[0].num_instances is not None:\n",
    "            num_instances = [pc.num_instances for pc in point_clouds]\n",
    "            max_num_instances = max(num_instances)\n",
    "            num_points_per_instance = torch.zeros(\n",
    "                batch_size, max_num_instances, dtype=torch.int32, device=device\n",
    "            )\n",
    "            instance_sem_labels = torch.full(\n",
    "                (batch_size, max_num_instances), -1, dtype=torch.int32, device=device\n",
    "            )\n",
    "            for i, pc in enumerate(point_clouds):\n",
    "                num_points_per_instance[i, :pc.num_instances] = pc.num_points_per_instance\n",
    "                instance_sem_labels[i, :pc.num_instances] = pc.instance_sem_labels\n",
    "        else:\n",
    "            num_instances = None\n",
    "            num_points_per_instance = None\n",
    "            instance_sem_labels = None\n",
    "\n",
    "        # 合并所有点云的实例区域信息（如果有）\n",
    "        if point_clouds[0].instance_regions is not None:\n",
    "            instance_regions = torch.cat([\n",
    "                pc.instance_regions for pc in point_clouds\n",
    "            ], dim=0)\n",
    "        else:\n",
    "            instance_regions = None\n",
    "\n",
    "        # 合并所有点云的体素信息，打标签，手动聚合，因为每一个本质上已经体素化了\n",
    "        voxel_batch_indices = torch.cat([\n",
    "            torch.full((\n",
    "                pc.voxel_coords.shape[0],), i, dtype=torch.int32, device=device\n",
    "            )\n",
    "            for i, pc in enumerate(point_clouds)\n",
    "        ], dim=0)\n",
    "        voxel_coords = torch.cat([\n",
    "            pc.voxel_coords for pc in point_clouds\n",
    "        ], dim=0)\n",
    "        voxel_coords = torch.cat([\n",
    "            voxel_batch_indices[:, None], voxel_coords\n",
    "        ], dim=-1)\n",
    "        voxel_features = torch.cat([\n",
    "            pc.voxel_features for pc in point_clouds\n",
    "        ], dim=0)\n",
    "\n",
    "        # 创建稀疏卷积张量\n",
    "        voxel_coords_range = np.max([\n",
    "            pc.voxel_coords_range for pc in point_clouds\n",
    "        ], axis=0)\n",
    "        voxel_tensor = spconv.SparseConvTensor(\n",
    "            voxel_features, voxel_coords,\n",
    "            spatial_shape=voxel_coords_range.tolist(),\n",
    "            batch_size=len(point_clouds),\n",
    "        )\n",
    "\n",
    "        # 合并每个点云的体素编号\n",
    "        pc_voxel_id = []\n",
    "        num_voxel_offset = 0\n",
    "        for pc in point_clouds:\n",
    "            pc.pc_voxel_id[pc.pc_voxel_id >= 0] += num_voxel_offset\n",
    "            pc_voxel_id.append(pc.pc_voxel_id)\n",
    "            num_voxel_offset += pc.voxel_coords.shape[0]\n",
    "        pc_voxel_id = torch.cat(pc_voxel_id, dim=0)\n",
    "\n",
    "        # 返回PointCloudBatch对象\n",
    "        return PointCloudBatch(\n",
    "            pc_ids=pc_ids,\n",
    "            points=points,\n",
    "            batch_indices=batch_indices,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "            voxel_tensor=voxel_tensor,\n",
    "            pc_voxel_id=pc_voxel_id,\n",
    "            sem_labels=sem_labels,\n",
    "            num_instances=num_instances,\n",
    "            instance_regions=instance_regions,\n",
    "            num_points_per_instance=num_points_per_instance,\n",
    "            instance_sem_labels=instance_sem_labels,\n",
    "            instance_labels=instance_labels,\n",
    "            gt_npcs=gt_npcs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions\n",
    "def feature_transform_reguliarzer(trans):\n",
    "    d = trans.size()[1] # k (bs, k, k)\n",
    "    I = torch.eye(d)[None, :, :] # no batch size\n",
    "    if trans.is_cuda:\n",
    "        I = I.cuda() # to cuda\n",
    "    loss = torch.mean(torch.norm(torch.bmm(trans, trans.transpose(2, 1)) - I, dim=(1, 2))) # 尽可能满足正交性质\n",
    "    return loss\n",
    "\n",
    "def apply_voxelization( # 这里进行体素化\n",
    "    pc: PointCloud, *, voxel_size: Tuple[float, float, float]\n",
    ") -> PointCloud:\n",
    "    pc = copy.copy(pc)\n",
    "\n",
    "    num_points = pc.points.shape[0]\n",
    "    pt_xyz = pc.points[:, :3]\n",
    "    points_range_min = pt_xyz.min(0)[0] - 1e-4\n",
    "    points_range_max = pt_xyz.max(0)[0] + 1e-4\n",
    "    voxel_features, voxel_coords, _, pc_voxel_id = voxelize(\n",
    "        pt_xyz, pc.points,\n",
    "        batch_offsets=torch.as_tensor([0, num_points], dtype=torch.int64, device = pt_xyz.device),\n",
    "        voxel_size=torch.as_tensor(voxel_size, device = pt_xyz.device),\n",
    "        points_range_min=torch.as_tensor(points_range_min, device = pt_xyz.device),\n",
    "        points_range_max=torch.as_tensor(points_range_max, device = pt_xyz.device),\n",
    "        reduction=\"mean\",\n",
    "    )\n",
    "    assert (pc_voxel_id >= 0).all()\n",
    "\n",
    "    voxel_coords_range = (voxel_coords.max(0)[0] + 1).clamp(min=128, max=None)\n",
    "\n",
    "    pc.voxel_features = voxel_features\n",
    "    pc.voxel_coords = voxel_coords\n",
    "    pc.voxel_coords_range = voxel_coords_range.tolist()\n",
    "    pc.pc_voxel_id = pc_voxel_id\n",
    "\n",
    "    return pc\n",
    "# 画框框\n",
    "def segmented_voxelize(\n",
    "    pt_xyz: torch.Tensor,  # 输入点云的坐标信息，形状为 (N, 3)，N 是点的数量\n",
    "    pt_features: torch.Tensor,  # 输入点云的特征信息，形状为 (N, C)，C 是特征的维度\n",
    "    segment_offsets: torch.Tensor,  # 分割信息的偏移量，形状为 (S+1,)，S 是分割的数量，表示每个分割在 pt_xyz 中的起始索引\n",
    "    segment_indices: torch.Tensor,  # 点云的索引信息，用于指示每个点属于哪个分割，形状为 (N,)\n",
    "    num_points_per_segment: torch.Tensor,  # 每个分割中的点的数量，形状为 (S,)\n",
    "    score_fullscale: float,  # 分割的缩放比例的全尺度参数\n",
    "    score_scale: float,  # 分割的缩放比例的尺度参数\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    # 计算每个分割的起始索引和结束索引\n",
    "    segment_offsets_begin = segment_offsets[:-1]\n",
    "    segment_offsets_end = segment_offsets[1:]\n",
    "\n",
    "    # 计算每个分割的中心坐标\n",
    "    segment_coords_mean = segmented_reduce(\n",
    "        pt_xyz, segment_offsets_begin, segment_offsets_end, mode=\"sum\"\n",
    "    ) / num_points_per_segment[:, None]\n",
    "\n",
    "    # 中心化点云数据\n",
    "    centered_points = pt_xyz - segment_coords_mean[segment_indices]\n",
    "\n",
    "    # 计算每个分割的包围盒的最小坐标和最大坐标\n",
    "    segment_coords_min = segmented_reduce(\n",
    "        centered_points, segment_offsets_begin, segment_offsets_end, mode=\"min\"\n",
    "    )\n",
    "    segment_coords_max = segmented_reduce(\n",
    "        centered_points, segment_offsets_begin, segment_offsets_end, mode=\"max\"\n",
    "    )\n",
    "\n",
    "    # 根据包围盒计算分割的缩放比例\n",
    "    segment_scales = 1. / (\n",
    "        (segment_coords_max - segment_coords_min) / score_fullscale\n",
    "    ).max(-1)[0] - 0.01\n",
    "    segment_scales = torch.clamp(segment_scales, min=None, max=score_scale)\n",
    "\n",
    "    # 计算分割的最小坐标和最大坐标\n",
    "    min_xyz = segment_coords_min * segment_scales[..., None]\n",
    "    max_xyz = segment_coords_max * segment_scales[..., None]\n",
    "\n",
    "    # 使用随机偏移以解决体素化后的点云坐标重叠问题\n",
    "    range_xyz = max_xyz - min_xyz\n",
    "    offsets = -min_xyz + torch.clamp(\n",
    "        score_fullscale - range_xyz - 0.001, min=0\n",
    "    ) * torch.rand(3, dtype=min_xyz.dtype, device=min_xyz.device) + torch.clamp(\n",
    "        score_fullscale - range_xyz + 0.001, max=0\n",
    "    ) * torch.rand(3, dtype=min_xyz.dtype, device=min_xyz.device)\n",
    "    segment_scales = segment_scales[segment_indices]\n",
    "    scaled_points = centered_points * segment_scales[..., None]\n",
    "    scaled_points += offsets[segment_indices]\n",
    "    scaled_points = scaled_points.cpu()\n",
    "    pt_features = pt_features.cpu()\n",
    "    segment_offsets = segment_offsets.cpu()\n",
    "    # 对点云进行体素化\n",
    "    voxel_features, voxel_coords, voxel_batch_indices, pc_voxel_id = voxelize(\n",
    "        scaled_points,\n",
    "        pt_features,\n",
    "        batch_offsets=segment_offsets.long(),\n",
    "        voxel_size=torch.as_tensor([1., 1., 1.], device=\"cpu\", dtype=torch.float32),\n",
    "        points_range_min=torch.as_tensor([0., 0., 0.], device=\"cpu\", dtype=torch.float32),\n",
    "        points_range_max=torch.as_tensor([score_fullscale, score_fullscale, score_fullscale], device=\"cpu\", dtype=torch.float32),\n",
    "        reduction=\"mean\",\n",
    "    )\n",
    "    # 更新体素的坐标信息，添加批次索引\n",
    "    voxel_coords = torch.cat([voxel_batch_indices[:, None], voxel_coords], dim=1)\n",
    "    voxel_features = voxel_features.to(\"cuda\")\n",
    "    voxel_coords = voxel_coords.to(\"cuda\")\n",
    "    pc_voxel_id = pc_voxel_id.to(\"cuda\")\n",
    "    return voxel_features, voxel_coords, pc_voxel_id\n",
    "# 聚类\n",
    "def cluster_proposals(\n",
    "    pt_xyz: torch.Tensor,\n",
    "    batch_indices: torch.Tensor,\n",
    "    batch_offsets: torch.Tensor,\n",
    "    sem_preds: torch.Tensor,\n",
    "    ball_query_radius: float,\n",
    "    max_num_points_per_query: int,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    根据给定的点云坐标、批次索引、语义预测等信息，使用球形查询进行提案聚类。\n",
    "\n",
    "    Args:\n",
    "        pt_xyz (torch.Tensor): 点云的坐标张量，形状为 (N, 3)，其中 N 是点的数量。\n",
    "        batch_indices (torch.Tensor): 点云的批次索引张量，形状为 (N,)。\n",
    "        batch_offsets (torch.Tensor): 批次偏移张量，形状为 (B+1,)，其中 B 是批次数。\n",
    "        sem_preds (torch.Tensor): 点云的语义预测张量，形状为 (N, 9)。\n",
    "        ball_query_radius (float): 球形查询半径。\n",
    "        max_num_points_per_query (int): 每个查询的最大点数。\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: 返回聚类后的提案标签张量和对应的排序索引张量。\n",
    "    \"\"\"\n",
    "    device = pt_xyz.device\n",
    "    index_dtype = batch_indices.dtype\n",
    "\n",
    "    # 使用球形查询进行点云聚类\n",
    "    clustered_indices, num_points_per_query = ball_query(\n",
    "        pt_xyz,\n",
    "        pt_xyz,\n",
    "        batch_indices,\n",
    "        batch_offsets,\n",
    "        ball_query_radius,\n",
    "        max_num_points_per_query,\n",
    "        point_labels=sem_preds,\n",
    "        query_labels=sem_preds,\n",
    "    )\n",
    "\n",
    "    # 构造聚类索引\n",
    "    ccl_indices_begin = torch.arange(\n",
    "        pt_xyz.shape[0], dtype=index_dtype, device=device\n",
    "    ) * max_num_points_per_query # (N * max,) 开始的索引\n",
    "    ccl_indices_end = ccl_indices_begin + num_points_per_query # 加一轮就是结束索引\n",
    "    ccl_indices = torch.stack([ccl_indices_begin, ccl_indices_end], dim=1) # (2, N*max) -> (N*max, 2)\n",
    "\n",
    "    # 执行连通组件标记并对聚类标签进行排序\n",
    "    cc_labels = connected_components_labeling(\n",
    "        ccl_indices.view(-1), clustered_indices.view(-1), compacted=False\n",
    "    )\n",
    "    sorted_cc_labels, sorted_indices = torch.sort(cc_labels)\n",
    "\n",
    "    return sorted_cc_labels, sorted_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based blocks\n",
    "class ResBlock(spconv.SparseModule):\n",
    "    def __init__(\n",
    "        self, in_channels: int, out_channels: int, norm_fn: nn.Module, indice_key=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if in_channels == out_channels:\n",
    "            self.shortcut = nn.Identity() # channel 相同就是 x \n",
    "        else:\n",
    "            # assert False\n",
    "            self.shortcut = spconv.SparseSequential( # feature 层面的全连接\n",
    "                spconv.SubMConv3d(in_channels, out_channels, kernel_size=1, \\\n",
    "                bias=False),\n",
    "                norm_fn(out_channels),\n",
    "            )\n",
    "\n",
    "        self.conv1 = spconv.SparseSequential(\n",
    "            spconv.SubMConv3d(\n",
    "                in_channels, out_channels, kernel_size=3,\n",
    "                padding=1, bias=False, indice_key=indice_key,\n",
    "            ),\n",
    "            norm_fn(out_channels),\n",
    "        )\n",
    "\n",
    "        self.conv2 = spconv.SparseSequential(\n",
    "            spconv.SubMConv3d(\n",
    "                out_channels, out_channels, kernel_size=3,\n",
    "                padding=1, bias=False, indice_key=indice_key,\n",
    "            ),\n",
    "            norm_fn(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: spconv.SparseConvTensor) -> spconv.SparseConvTensor:\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = x.replace_feature(F.relu(x.features)) # 相当于ReLU\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = x.replace_feature(F.relu(x.features + shortcut.features))\n",
    "\n",
    "        return x\n",
    "\n",
    "class UBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: List[int],\n",
    "        block_fn: nn.Module,\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        indice_key_id: int = 1, # 递归计数器\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        encoder_blocks = [\n",
    "            block_fn(\n",
    "                channels[0], channels[0], norm_fn, indice_key=f\"subm{indice_key_id}\"\n",
    "            )\n",
    "            for _ in range(block_repeat)\n",
    "        ]\n",
    "        self.encoder_blocks = spconv.SparseSequential(*encoder_blocks) # 同层次几层\n",
    "\n",
    "        if len(channels) > 1:\n",
    "            self.downsample = spconv.SparseSequential(\n",
    "                spconv.SparseConv3d(\n",
    "                    channels[0], channels[1], kernel_size=2, stride=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[1]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            self.ublock = UBlock(\n",
    "                channels[1:], block_fn, block_repeat, norm_fn, indice_key_id + 1\n",
    "            ) # 这也能递归？？！\n",
    "\n",
    "            self.upsample = spconv.SparseSequential(\n",
    "                spconv.SparseInverseConv3d(\n",
    "                    channels[1], channels[0], kernel_size=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            decoder_blocks = [\n",
    "                block_fn(\n",
    "                    channels[0] * 2, channels[0], norm_fn,\n",
    "                    indice_key=f\"subm{indice_key_id}\",\n",
    "                ),\n",
    "            ]\n",
    "            for _ in range(block_repeat -1):\n",
    "                decoder_blocks.append(\n",
    "                    block_fn(\n",
    "                        channels[0], channels[0], norm_fn,\n",
    "                        indice_key=f\"subm{indice_key_id}\",\n",
    "                    )\n",
    "                )\n",
    "            self.decoder_blocks = spconv.SparseSequential(*decoder_blocks)\n",
    "\n",
    "    def forward(self, x: spconv.SparseConvTensor) -> spconv.SparseConvTensor:\n",
    "        x = self.encoder_blocks(x) # 平层过几次\n",
    "        shortcut = x\n",
    "\n",
    "        if len(self.channels) > 1: # 返回条件\n",
    "\n",
    "            x = self.downsample(x)\n",
    "            x = self.ublock(x) # 这也能递归？不愧是北大！艺术\n",
    "            x = self.upsample(x)\n",
    "\n",
    "            x = x.replace_feature(torch.cat([x.features, shortcut.features],\\\n",
    "                 dim=-1)) # shortcut\n",
    "            x = self.decoder_blocks(x) # 每层都有decoder_blocks, 因为cut了，所以feature * 2\n",
    "\n",
    "        return x\n",
    "    \n",
    "class SparseUNet(nn.Module):\n",
    "    def __init__(self, stem: nn.Module, ublock: UBlock):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = stem\n",
    "        self.ublock = ublock # 掉了一层壳子\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stem is not None:\n",
    "            x = self.stem(x)\n",
    "        x = self.ublock(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod # classmethod是个python特殊的方法\n",
    "    def build( # 相当于另一个构造函数\n",
    "        cls,\n",
    "        in_channels: int,\n",
    "        channels: List[int],\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        without_stem: bool = False,\n",
    "    ):\n",
    "        if not without_stem:\n",
    "            stem = spconv.SparseSequential(\n",
    "                spconv.SubMConv3d(\n",
    "                    in_channels, channels[0], kernel_size=3, # 把inchannel和channel对应上\n",
    "                    padding=1, bias=False, indice_key=\"subm1\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            stem = spconv.SparseSequential( # 通道一样就不管\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        block = UBlock(channels, ResBlock, block_repeat, norm_fn, \\\n",
    "            indice_key_id=1)\n",
    "\n",
    "        return SparseUNet(stem, block)\n",
    "\n",
    "class UBlock_NoSkip(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels: List[int],\n",
    "        block_fn: nn.Module,\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        indice_key_id: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        encoder_blocks = [\n",
    "            block_fn(\n",
    "                channels[0], channels[0], norm_fn, indice_key=f\"subm{indice_key_id}\"\n",
    "            )\n",
    "            for _ in range(block_repeat)\n",
    "        ]\n",
    "        self.encoder_blocks = spconv.SparseSequential(*encoder_blocks)\n",
    "\n",
    "        if len(channels) > 1:\n",
    "            self.downsample = spconv.SparseSequential(\n",
    "                spconv.SparseConv3d(\n",
    "                    channels[0], channels[1], kernel_size=2, stride=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[1]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            self.ublock = UBlock(\n",
    "                channels[1:], block_fn, block_repeat, norm_fn, indice_key_id + 1\n",
    "            )\n",
    "\n",
    "            self.upsample = spconv.SparseSequential(\n",
    "                spconv.SparseInverseConv3d(\n",
    "                    channels[1], channels[0], kernel_size=2,\n",
    "                    bias=False, indice_key=f\"spconv{indice_key_id}\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "            decoder_blocks = [\n",
    "                block_fn(\n",
    "                    channels[0], channels[0], norm_fn,\n",
    "                    indice_key=f\"subm{indice_key_id}\",\n",
    "                ),\n",
    "            ]\n",
    "            for _ in range(block_repeat -1):\n",
    "                decoder_blocks.append(\n",
    "                    block_fn(\n",
    "                        channels[0], channels[0], norm_fn,\n",
    "                        indice_key=f\"subm{indice_key_id}\",\n",
    "                    )\n",
    "                )\n",
    "            self.decoder_blocks = spconv.SparseSequential(*decoder_blocks)\n",
    "\n",
    "    def forward(self, x: spconv.SparseConvTensor) -> spconv.SparseConvTensor:\n",
    "        x = self.encoder_blocks(x)\n",
    "        # shortcut = x\n",
    "\n",
    "        if len(self.channels) > 1:\n",
    "            x = self.downsample(x)\n",
    "            x = self.ublock(x)\n",
    "            x = self.upsample(x)\n",
    "\n",
    "            # x = x.replace_feature(torch.cat([x.features, shortcut.features],\\\n",
    "            #      dim=-1)) # 注释几行话而已\n",
    "            x = self.decoder_blocks(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SparseUNet_NoSkip(nn.Module): # 同理注释\n",
    "    def __init__(self, stem: nn.Module, ublock: UBlock_NoSkip):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = stem\n",
    "        self.ublock = ublock\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stem is not None:\n",
    "            x = self.stem(x)\n",
    "        x = self.ublock(x)\n",
    "        return x\n",
    "\n",
    "    @classmethod\n",
    "    def build(\n",
    "        cls,\n",
    "        in_channels: int,\n",
    "        channels: List[int],\n",
    "        block_repeat: int,\n",
    "        norm_fn: nn.Module,\n",
    "        without_stem: bool = False,\n",
    "    ):\n",
    "        if not without_stem:\n",
    "            stem = spconv.SparseSequential(\n",
    "                spconv.SubMConv3d(\n",
    "                    in_channels, channels[0], kernel_size=3,\n",
    "                    padding=1, bias=False, indice_key=\"subm1\",\n",
    "                ),\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "        else:\n",
    "            stem = spconv.SparseSequential(\n",
    "                norm_fn(channels[0]),\n",
    "                nn.ReLU(),\n",
    "            )\n",
    "\n",
    "        block = UBlock(channels, ResBlock, block_repeat, norm_fn, \\\n",
    "            indice_key_id=1)\n",
    "\n",
    "        return SparseUNet(stem, block)\n",
    "\n",
    "class STN3d(nn.Module):\n",
    "    def __init__(self, channel): # channel 看上去应该默认为3\n",
    "        super(STN3d, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0] # (bs, features, points)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x))) # 一维卷积，放大features维度层次\n",
    "        x = torch.max(x, 2, keepdim=True)[0] # 点归并成最大features\n",
    "        x = x.view(-1, 1024) # 展平 \n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x))) # 连接到256层特征\n",
    "        x = self.fc3(x) # 9层\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32))).view(1, 9).repeat(\n",
    "            batchsize, 1) # (bs, 1, 9) #[1 0 0]\n",
    "        if x.is_cuda: # is_cuda返回0     [0 1 0]\n",
    "            iden = iden.cuda() #          [0 0 1]\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3) # 预测的是一个单位阵，加上了一个矩阵\n",
    "        return x\n",
    "\n",
    "class STNkd(nn.Module):\n",
    "    def __init__(self, k=64): # 上升到了k维\n",
    "        super(STNkd, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(k, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, k * k) # 输出是k * k矩阵\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.max(x, 2, keepdim=True)[0]\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.eye(self.k).flatten().astype(np.float32))).view(1, self.k * self.k).repeat(\n",
    "            batchsize, 1) # k维度单位阵\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, self.k, self.k)\n",
    "        return x\n",
    "\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self, global_feat=True, feature_transform=False, channel=3):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.stn = STN3d(channel) # 3维\n",
    "        self.conv1 = torch.nn.Conv1d(channel, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.global_feat = global_feat\n",
    "        self.feature_transform = feature_transform\n",
    "        if self.feature_transform:\n",
    "            self.fstn = STNkd(k=64) # 特征也能变换\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, D, N = x.size()\n",
    "        trans = self.stn(x) # 矩阵\n",
    "        x = x.transpose(2, 1) # 交换 D, N，为了矩阵乘法\n",
    "        if D > 3: # 分割 features\n",
    "            feature = x[:, :, 3:]\n",
    "            x = x[:, :, :3]\n",
    "        x = torch.bmm(x, trans) # x 位置进行变换\n",
    "        if D > 3:\n",
    "            x = torch.cat([x, feature], dim=2)\n",
    "        x = x.transpose(2, 1) # 变回来\n",
    "        x = F.relu(self.bn1(self.conv1(x))) # 增广D\n",
    "\n",
    "        if self.feature_transform:\n",
    "            trans_feat = self.fstn(x)\n",
    "            x = x.transpose(2, 1)\n",
    "            x = torch.bmm(x, trans_feat) # 变换features\n",
    "            x = x.transpose(2, 1)\n",
    "        else:\n",
    "            trans_feat = None\n",
    "\n",
    "        pointfeat = x # shortcut\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = torch.max(x, 2, keepdim=True)[0] # 增广，features取N上面的最大\n",
    "        x = x.view(-1, 1024) # 展平\n",
    "        if self.global_feat:\n",
    "            return x, trans, trans_feat # 返回的本质是1024feature和\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, N) # (bs, 1024, N) N个是一样的\n",
    "            return torch.cat([x, pointfeat], 1), trans, trans_feat # 决定是否concat，增广是为了concat\n",
    "\n",
    "class PointNetSegBackbone(nn.Module):\n",
    "    def __init__(self, pc_dim, fea_dim):\n",
    "        super(PointNetSegBackbone, self).__init__()\n",
    "        self.fea_dim = fea_dim\n",
    "        self.feat = PointNetEncoder(global_feat=False, feature_transform=True, channel=3+pc_dim)\n",
    "        self.conv1 = torch.nn.Conv1d(1088, 512, 1) # 1024 + 64 feature位置\n",
    "        self.conv2 = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(256, 256, 1)\n",
    "        self.conv4 = torch.nn.Conv1d(256, self.fea_dim, 1) # 干到输出的features\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        n_pts = x.size()[2]\n",
    "        x, trans, trans_feat = self.feat(x)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.conv4(x) # 给feature降维 \n",
    "        fea = x.transpose(2,1).contiguous() # D, N 换位\n",
    "        return fea\n",
    "        # x = F.log_softmax(x.view(-1,self.k), dim=-1)\n",
    "        # x = x.view(batchsize, n_pts, self.k)\n",
    "        # return x, trans_feat\n",
    "\n",
    "class get_loss(torch.nn.Module):\n",
    "    def __init__(self, mat_diff_loss_scale=0.001):\n",
    "        super(get_loss, self).__init__()\n",
    "        self.mat_diff_loss_scale = mat_diff_loss_scale\n",
    "\n",
    "    def forward(self, pred, target, trans_feat, weight):\n",
    "        loss = F.nll_loss(pred, target, weight = weight) # ?\n",
    "        mat_diff_loss = feature_transform_reguliarzer(trans_feat) # 正交损失\n",
    "        total_loss = loss + mat_diff_loss * self.mat_diff_loss_scale # 你也没返回loss啊\n",
    "\n",
    "class PointNetBackbone(nn.Module): # 这个就是把pointnet包调出来\n",
    "    def __init__(\n",
    "        self,\n",
    "        pc_dim: int,\n",
    "        feature_dim: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pc_dim = pc_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.backbone = PointNetSegBackbone(self.pc_dim,self.feature_dim)\n",
    "    \n",
    "    def forward(self, input_pc):\n",
    "        others = {}\n",
    "        return self.backbone(input_pc), others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "pc_xyzs = [torch.randn(1024, 3), torch.randn(512, 3)]\n",
    "feats = [torch.randn(1024, 6), torch.randn(512, 6)]\n",
    "voxel_feats_list = []\n",
    "voxel_coords_list = []\n",
    "voxel_coords_range_list = []\n",
    "for pc_xyz, feat in zip(pc_xyzs, feats):\n",
    "    points_range_min = pc_xyz.min(0)[0] - 1e-4\n",
    "    points_range_max = pc_xyz.max(0)[0] + 1e-4\n",
    "    num_points = pc_xyz.shape[0]\n",
    "    voxel_features, voxel_coords, _, pc_voxel_id = voxelize(\n",
    "        pc_xyz.cuda(), feat.cuda(),\n",
    "        batch_offsets=torch.as_tensor([0, num_points], dtype=torch.int64, device = \"cuda\"),\n",
    "        voxel_size=torch.as_tensor([0.01,0.01,0.01], device = \"cuda\"),\n",
    "        points_range_min=torch.as_tensor(points_range_min, device = \"cuda\"),\n",
    "        points_range_max=torch.as_tensor(points_range_max, device = \"cuda\"),\n",
    "        reduction=\"mean\",\n",
    "    )\n",
    "    voxel_coords_range = (voxel_coords.max(0)[0] + 1).clamp(min=128, max=None)\n",
    "    voxel_coords_range_list.append(voxel_coords_range.cpu().numpy())\n",
    "    voxel_feats_list.append(voxel_features)\n",
    "    voxel_coords_list.append(voxel_coords)\n",
    "\n",
    "# 合并所有点云的体素信息，打标签，手动聚合，因为每一个本质上已经体素化了\n",
    "voxel_batch_indices = torch.cat([\n",
    "    torch.full(\n",
    "        (pc.shape[0],), i, dtype=torch.int32, device=\"cuda\"\n",
    "    )\n",
    "    for i, pc in enumerate(voxel_coords_list)\n",
    "], dim=0)\n",
    "voxel_coords = torch.cat([\n",
    "    pc for pc in voxel_coords_list\n",
    "], dim=0)\n",
    "voxel_coords = torch.cat([\n",
    "    voxel_batch_indices[:, None], voxel_coords\n",
    "], dim=-1)\n",
    "voxel_features = torch.cat([\n",
    "    pc for pc in voxel_feats_list\n",
    "], dim=0)\n",
    "\n",
    "# 创建稀疏卷积张量\n",
    "voxel_coords_ranges = np.max([\n",
    "    voxel_coords_range for voxel_coords_range in voxel_coords_range_list\n",
    "], axis=0) # 取三个坐标轴的最大值，用于指定体素的范围\n",
    "\n",
    "voxel_tensor = spconv.SparseConvTensor(\n",
    "    voxel_features.to(\"cuda\"), voxel_coords.to(\"cuda\"),\n",
    "    spatial_shape=voxel_coords_ranges.tolist(),\n",
    "    batch_size=2,\n",
    ")\n",
    "\n",
    "instance_labels = np.random.randint(0, 10, size=100)  # 100个随机实例标签，范围在0到9之间\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointNetBackbone(\n",
      "  (backbone): PointNetSegBackbone(\n",
      "    (feat): PointNetEncoder(\n",
      "      (stn): STN3d(\n",
      "        (conv1): Conv1d(67, 64, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
      "        (relu): ReLU()\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv1d(67, 64, kernel_size=(1,), stride=(1,))\n",
      "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (fstn): STNkd(\n",
      "        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "        (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
      "        (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
      "        (relu): ReLU()\n",
      "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (conv1): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
      "    (conv2): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv3): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    (conv4): Conv1d(256, 10, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "torch.Size([64, 2048, 10])\n"
     ]
    }
   ],
   "source": [
    "model = PointNetBackbone(64, 10)\n",
    "model = model.to(\"cuda\")\n",
    "print(model)\n",
    "inputs = torch.randn(64, 64+3, 2048).to(\"cuda\")\n",
    "# print(model.device)\n",
    "# print(inputs.device)\n",
    "outputs = model(inputs)[0]\n",
    "print(outputs.size()) # 输出(64, 2048, 10) -> (bs, N, fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseUNet(\n",
      "  (stem): SparseSequential(\n",
      "    (0): SubMConv3d(6, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "    (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (ublock): UBlock(\n",
      "    (encoder_blocks): SparseSequential(\n",
      "      (0): ResBlock(\n",
      "        (shortcut): Identity()\n",
      "        (conv1): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (shortcut): Identity()\n",
      "        (conv1): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (downsample): SparseSequential(\n",
      "      (0): SparseConv3d(16, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "      (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (ublock): UBlock(\n",
      "      (encoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): SparseSequential(\n",
      "        (0): SparseConv3d(32, 48, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (ublock): UBlock(\n",
      "        (encoder_blocks): SparseSequential(\n",
      "          (0): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): SparseSequential(\n",
      "          (0): SparseConv3d(48, 64, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (ublock): UBlock(\n",
      "          (encoder_blocks): SparseSequential(\n",
      "            (0): ResBlock(\n",
      "              (shortcut): Identity()\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (shortcut): Identity()\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SparseSequential(\n",
      "            (0): SparseConv3d(64, 80, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (ublock): UBlock(\n",
      "            (encoder_blocks): SparseSequential(\n",
      "              (0): ResBlock(\n",
      "                (shortcut): Identity()\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResBlock(\n",
      "                (shortcut): Identity()\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (downsample): SparseSequential(\n",
      "              (0): SparseConv3d(80, 96, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (ublock): UBlock(\n",
      "              (encoder_blocks): SparseSequential(\n",
      "                (0): ResBlock(\n",
      "                  (shortcut): Identity()\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): ResBlock(\n",
      "                  (shortcut): Identity()\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (downsample): SparseSequential(\n",
      "                (0): SparseConv3d(96, 112, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU()\n",
      "              )\n",
      "              (ublock): UBlock(\n",
      "                (encoder_blocks): SparseSequential(\n",
      "                  (0): ResBlock(\n",
      "                    (shortcut): Identity()\n",
      "                    (conv1): SparseSequential(\n",
      "                      (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv2): SparseSequential(\n",
      "                      (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): ResBlock(\n",
      "                    (shortcut): Identity()\n",
      "                    (conv1): SparseSequential(\n",
      "                      (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv2): SparseSequential(\n",
      "                      (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (upsample): SparseSequential(\n",
      "                (0): SparseInverseConv3d(112, 96, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU()\n",
      "              )\n",
      "              (decoder_blocks): SparseSequential(\n",
      "                (0): ResBlock(\n",
      "                  (shortcut): SparseSequential(\n",
      "                    (0): SubMConv3d(192, 96, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(192, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): ResBlock(\n",
      "                  (shortcut): Identity()\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (upsample): SparseSequential(\n",
      "              (0): SparseInverseConv3d(96, 80, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (decoder_blocks): SparseSequential(\n",
      "              (0): ResBlock(\n",
      "                (shortcut): SparseSequential(\n",
      "                  (0): SubMConv3d(160, 80, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(160, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResBlock(\n",
      "                (shortcut): Identity()\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (upsample): SparseSequential(\n",
      "            (0): SparseInverseConv3d(80, 64, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (decoder_blocks): SparseSequential(\n",
      "            (0): ResBlock(\n",
      "              (shortcut): SparseSequential(\n",
      "                (0): SubMConv3d(128, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(128, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (shortcut): Identity()\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): SparseSequential(\n",
      "          (0): SparseInverseConv3d(64, 48, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (decoder_blocks): SparseSequential(\n",
      "          (0): ResBlock(\n",
      "            (shortcut): SparseSequential(\n",
      "              (0): SubMConv3d(96, 48, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(96, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): SparseSequential(\n",
      "        (0): SparseInverseConv3d(48, 32, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (decoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): SparseSequential(\n",
      "            (0): SubMConv3d(64, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(64, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (upsample): SparseSequential(\n",
      "      (0): SparseInverseConv3d(32, 16, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "      (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (decoder_blocks): SparseSequential(\n",
      "      (0): ResBlock(\n",
      "        (shortcut): SparseSequential(\n",
      "          (0): SubMConv3d(32, 16, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv1): SparseSequential(\n",
      "          (0): SubMConv3d(32, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (shortcut): Identity()\n",
      "        (conv1): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (conv2): SparseSequential(\n",
      "          (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([1536, 6])\n",
      "torch.Size([1536, 4])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "SparseConvTensor[shape=torch.Size([1536, 16])]\n"
     ]
    }
   ],
   "source": [
    "sparseunet = SparseUNet.build(6, [16,32,48,64,80,96,112], 2, functools.partial(nn.BatchNorm1d, eps=1e-4, momentum=0.1))\n",
    "sparseunet.to(\"cuda\")\n",
    "print(sparseunet)\n",
    "\n",
    "print(voxel_features.size())\n",
    "print(voxel_coords.size())\n",
    "print(_.size())\n",
    "print(pc_voxel_id.size())\n",
    "\n",
    "print(sparseunet(voxel_tensor)) # output: (N, 16), batch size inside N. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_part_classes: int,\n",
    "        backbone_type: str = \"SparseUNet\",\n",
    "        backbone_cfg: Dict = {},\n",
    "        learning_rate: float = 1e-3,\n",
    "        # semantic segmentation\n",
    "        ignore_sem_label: int = -100,\n",
    "        use_sem_focal_loss: bool = True,\n",
    "        use_sem_dice_loss: bool = True,\n",
    "        # instance segmentation\n",
    "        instance_seg_cfg: Dict = {},\n",
    "        # npcs segmentation\n",
    "        symmetry_indices: List = [],\n",
    "        # training\n",
    "        training_schedule: List = [],\n",
    "        # validation\n",
    "        val_score_threshold: float = 0.09,\n",
    "        val_min_num_points_per_proposal: int = 3,\n",
    "        val_nms_iou_threshold: float = 0.3,\n",
    "        val_ap_iou_threshold: float = 0.5,\n",
    "        # testing\n",
    "        visualize_cfg: Dict = {},\n",
    "        \n",
    "        debug: bool = True,\n",
    "        ckpt: str = \"\", # type: ignore\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.validation_step_outputs = []\n",
    "        self.device = \"cuda\"\n",
    "        self.in_channels = in_channels\n",
    "        self.num_part_classes = num_part_classes\n",
    "        self.backbone_type = backbone_type\n",
    "        self.backbone_cfg = backbone_cfg\n",
    "        self.learning_rate = learning_rate\n",
    "        self.ignore_sem_label = ignore_sem_label\n",
    "        self.use_sem_focal_loss = use_sem_focal_loss\n",
    "        self.use_sem_dice_loss = use_sem_dice_loss\n",
    "        self.visualize_cfg = visualize_cfg\n",
    "        self.start_scorenet, self.start_npcs = training_schedule\n",
    "        self.start_clustering = min(self.start_scorenet, self.start_npcs)\n",
    "        self.val_nms_iou_threshold = val_nms_iou_threshold\n",
    "        self.val_ap_iou_threshold = val_ap_iou_threshold\n",
    "        self.val_score_threshold = val_score_threshold\n",
    "        self.val_min_num_points_per_proposal = val_min_num_points_per_proposal\n",
    "        self.symmetry_indices = torch.as_tensor(symmetry_indices, dtype=torch.int64).to(self.device)\n",
    "\n",
    "        self.ball_query_radius = instance_seg_cfg[\"ball_query_radius\"]\n",
    "        self.max_num_points_per_query = instance_seg_cfg[\"max_num_points_per_query\"]\n",
    "        self.min_num_points_per_proposal = instance_seg_cfg[\"min_num_points_per_proposal\"]\n",
    "        self.max_num_points_per_query_shift = instance_seg_cfg[\"max_num_points_per_query_shift\"]\n",
    "        self.score_fullscale = instance_seg_cfg[\"score_fullscale\"]\n",
    "        self.score_scale = instance_seg_cfg[\"score_scale\"]\n",
    "        \n",
    "        \n",
    "        ## network\n",
    "        norm_fn = functools.partial(nn.BatchNorm1d, eps=1e-4, momentum=0.1)\n",
    "        if self.backbone_type == \"SparseUNet\":\n",
    "            channels = self.backbone_cfg[\"channels\"]\n",
    "            block_repeat = self.backbone_cfg[\"block_repeat\"]\n",
    "            fea_dim = channels[0]\n",
    "            self.backbone = SparseUNet.build(in_channels, channels, block_repeat, norm_fn)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.sem_seg_head = nn.Linear(fea_dim, self.num_part_classes)\n",
    "        # offset prediction\n",
    "        self.offset_head = nn.Sequential(\n",
    "            nn.Linear(fea_dim, fea_dim),\n",
    "            norm_fn(fea_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(fea_dim, 3),\n",
    "        )\n",
    "        \n",
    "        self.score_unet = SparseUNet.build( # \n",
    "            fea_dim, channels[:2], block_repeat, norm_fn, without_stem=True\n",
    "        )\n",
    "        self.score_head = nn.Linear(fea_dim, self.num_part_classes - 1) # link to 10 - 1 = 9 class \n",
    "        \n",
    "        \n",
    "        self.npcs_unet = SparseUNet.build( # masked fea to npcs\n",
    "            fea_dim, channels[:2], block_repeat, norm_fn, without_stem=True\n",
    "        )\n",
    "        self.npcs_head = nn.Linear(fea_dim, 3 * (self.num_part_classes - 1)) # 27 \n",
    "        \n",
    "        (\n",
    "            symmetry_matrix_1, symmetry_matrix_2, symmetry_matrix_3\n",
    "        ) = get_symmetry_matrix()\n",
    "        self.symmetry_matrix_1 = symmetry_matrix_1\n",
    "        self.symmetry_matrix_2 = symmetry_matrix_2\n",
    "        self.symmetry_matrix_3 = symmetry_matrix_3\n",
    "    def forward(\n",
    "        self,\n",
    "        point_clouds: List[PointCloud],\n",
    "    ):\n",
    "        batch_size = len(point_clouds)\n",
    "        \n",
    "        # data batch parsing\n",
    "        data_batch = PointCloud.collate(point_clouds)\n",
    "        points = data_batch.points\n",
    "        sem_labels = data_batch.sem_labels\n",
    "        pc_ids = data_batch.pc_ids\n",
    "        instance_regions = data_batch.instance_regions\n",
    "        instance_labels = data_batch.instance_labels\n",
    "        batch_indices = data_batch.batch_indices\n",
    "        instance_sem_labels = data_batch.instance_sem_labels\n",
    "        num_points_per_instance = data_batch.num_points_per_instance\n",
    "        gt_npcs = data_batch.gt_npcs\n",
    "        \n",
    "        \n",
    "        pt_xyz = points[:, :3]\n",
    "        # cls_labels.to(pt_xyz.device)\n",
    "\n",
    "        pc_feature = self.forward_backbone(pc_batch=data_batch)\n",
    "\n",
    "        # semantic segmentation\n",
    "        sem_logits = self.forward_sem_seg(pc_feature) # (N, 9)\n",
    "        \n",
    "        sem_preds = torch.argmax(sem_logits.detach(), dim=-1) # (N)\n",
    "        # no loss, only forward \n",
    "\n",
    "        sem_seg = Segmentation(\n",
    "            batch_size=batch_size,\n",
    "            sem_preds=sem_preds,\n",
    "            sem_labels=None,\n",
    "            all_accu=None,\n",
    "            pixel_accu=None,)\n",
    "        \n",
    "        offsets_preds = self.forward_offset(pc_feature) # (N, 3)\n",
    "\n",
    "        voxel_tensor, pc_voxel_id, proposals = self.proposal_clustering_and_revoxelize(\n",
    "            pt_xyz = pt_xyz,\n",
    "            batch_indices=batch_indices,\n",
    "            pt_features=pc_feature,\n",
    "            sem_preds=sem_preds,\n",
    "            offset_preds=offsets_preds,\n",
    "            instance_labels=instance_labels,\n",
    "        )\n",
    "        \n",
    "        if sem_labels is not None and proposals is not None:\n",
    "            proposals.sem_labels = sem_labels[proposals.valid_mask][\n",
    "                proposals.sorted_indices\n",
    "            ]\n",
    "        if proposals is not None:\n",
    "            proposals.instance_sem_labels = instance_sem_labels\n",
    "\n",
    "                \n",
    "        # clustering and scoring\n",
    "        score_logits = self.forward_proposal_score(\n",
    "            voxel_tensor, pc_voxel_id, proposals\n",
    "        ) # type: ignore\n",
    "        proposal_offsets_begin = proposals.proposal_offsets[:-1].long() # type: ignore\n",
    "\n",
    "        if proposals.sem_labels is not None: # type: ignore\n",
    "            proposal_sem_labels = proposals.sem_labels[proposal_offsets_begin].long() # type: ignore\n",
    "        else:\n",
    "            proposal_sem_labels = proposals.sem_preds[proposal_offsets_begin].long() # type: ignore\n",
    "        score_logits = score_logits.gather(\n",
    "            1, proposal_sem_labels[:, None] - 1\n",
    "        ).squeeze(1)\n",
    "        proposals.score_preds = score_logits.detach().sigmoid() # type: ignore\n",
    "\n",
    "            \n",
    "\n",
    "        npcs_logits = self.forward_proposal_npcs(\n",
    "            voxel_tensor, pc_voxel_id\n",
    "        )\n",
    "\n",
    "        \n",
    "        # no total loss\n",
    "        # loss = loss_sem_seg + loss_offset_dist + loss_offset_dir + loss_prop_score + loss_prop_npcs\n",
    "\n",
    "        return pc_ids, sem_seg, proposals # 索引，实例分隔，候选框，(损失)\n",
    "    def forward_backbone(\n",
    "        self,\n",
    "        pc_batch: PointCloudBatch,\n",
    "    ):\n",
    "        if self.backbone_type == \"SparseUNet\":\n",
    "            voxel_tensor = pc_batch.voxel_tensor\n",
    "            pc_voxel_id = pc_batch.pc_voxel_id\n",
    "            voxel_features = self.backbone(voxel_tensor)\n",
    "            pc_feature = voxel_features.features[pc_voxel_id]\n",
    "        else:\n",
    "            raise ValueError\n",
    "        \n",
    "        return pc_feature\n",
    "    def forward_sem_seg( # 语义分割，每个点的\n",
    "        self,\n",
    "        pc_feature: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        sem_logits = self.sem_seg_head(pc_feature) # (N, 16) to (N, 9)\n",
    "\n",
    "        return sem_logits\n",
    "    def forward_offset(\n",
    "        self,   \n",
    "        pc_feature: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        offset = self.offset_head(pc_feature) # (N, 3)\n",
    "\n",
    "        return offset\n",
    "    def proposal_clustering_and_revoxelize(\n",
    "        self,\n",
    "        pt_xyz: torch.Tensor,  # 输入点云的坐标信息，形状为 (N, 3)，N 是点的数量\n",
    "        batch_indices: torch.Tensor,  # 每个点所属的批次索引，形状为 (N,)\n",
    "        pt_features: torch.Tensor,  # 输入点云的特征信息，形状为 (N, C)，C 是特征的维度\n",
    "        sem_preds: torch.Tensor,  # 每个点的语义预测，形状为 (N, 9)\n",
    "        offset_preds: torch.Tensor,  # 每个点的偏移预测，形状为 (N, 3)\n",
    "        instance_labels: Optional[torch.Tensor],  # 每个点的实例标签，形状为 (N, 9)，可选参数，可能为空\n",
    "    ):\n",
    "        device = self.device\n",
    "        # 过滤掉语义预测为零的点\n",
    "        if instance_labels is not None:\n",
    "            valid_mask = (sem_preds > 0) & (instance_labels >= 0)\n",
    "        else:\n",
    "            valid_mask = sem_preds > 0\n",
    "        # 根据有效掩码过滤输入数据\n",
    "        pt_xyz = pt_xyz[valid_mask]\n",
    "        batch_indices = batch_indices[valid_mask]\n",
    "        pt_features = pt_features[valid_mask]\n",
    "        sem_preds = sem_preds[valid_mask].int()\n",
    "        offset_preds = offset_preds[valid_mask]\n",
    "        if instance_labels is not None:\n",
    "            instance_labels = instance_labels[valid_mask]\n",
    "            \n",
    "        # get batch offsets (csr) from batch indices\n",
    "        _, batch_indices_compact, num_points_per_batch = torch.unique_consecutive( # 找不同\n",
    "            batch_indices, return_inverse=True, return_counts=True\n",
    "        )\n",
    "        batch_indices_compact = batch_indices_compact.int()\n",
    "        batch_offsets = torch.zeros(\n",
    "            (num_points_per_batch.shape[0] + 1,), dtype=torch.int32, device=device\n",
    "        )\n",
    "        batch_offsets[1:] = num_points_per_batch.cumsum(0)\n",
    "        \n",
    "        # cluster proposals: dual set\n",
    "        sorted_cc_labels, sorted_indices = cluster_proposals( # 绝对坐标聚类\n",
    "            pt_xyz, batch_indices_compact, batch_offsets, sem_preds,\n",
    "            self.ball_query_radius, self.max_num_points_per_query,\n",
    "        )\n",
    "\n",
    "        sorted_cc_labels_shift, sorted_indices_shift = cluster_proposals( # 相对坐标聚类\n",
    "            pt_xyz + offset_preds, batch_indices_compact, batch_offsets, sem_preds,\n",
    "            self.ball_query_radius, self.max_num_points_per_query_shift,\n",
    "        )\n",
    "        \n",
    "        # combine clusters\n",
    "        sorted_cc_labels = torch.cat([\n",
    "            sorted_cc_labels,\n",
    "            sorted_cc_labels_shift + sorted_cc_labels.shape[0],\n",
    "        ], dim=0)\n",
    "        sorted_indices = torch.cat([sorted_indices, sorted_indices_shift], dim=0)\n",
    "\n",
    "        # compact the proposal ids\n",
    "        _, proposal_indices, num_points_per_proposal = torch.unique_consecutive( # 找重复元素\n",
    "            sorted_cc_labels, return_inverse=True, return_counts=True\n",
    "        )\n",
    "\n",
    "        # remove small proposals\n",
    "        valid_proposal_mask = (\n",
    "            num_points_per_proposal >= self.min_num_points_per_proposal # 直接删过少的\n",
    "        )\n",
    "        # proposal to point\n",
    "        valid_point_mask = valid_proposal_mask[proposal_indices] # mask的mask\n",
    "\n",
    "        sorted_indices = sorted_indices[valid_point_mask]\n",
    "        if sorted_indices.shape[0] == 0:\n",
    "            return None, None, None\n",
    "\n",
    "        batch_indices = batch_indices[sorted_indices]\n",
    "        pt_xyz = pt_xyz[sorted_indices]\n",
    "        pt_features = pt_features[sorted_indices]\n",
    "        sem_preds = sem_preds[sorted_indices]\n",
    "        if instance_labels is not None:\n",
    "            instance_labels = instance_labels[sorted_indices]\n",
    "\n",
    "        # re-compact the proposal ids 保留有效的框\n",
    "        proposal_indices = proposal_indices[valid_point_mask]\n",
    "        _, proposal_indices, num_points_per_proposal = torch.unique_consecutive(\n",
    "            proposal_indices, return_inverse=True, return_counts=True\n",
    "        )\n",
    "        num_proposals = num_points_per_proposal.shape[0]\n",
    "\n",
    "        # get proposal batch offsets\n",
    "        proposal_offsets = torch.zeros(\n",
    "            num_proposals + 1, dtype=torch.int32, device=device\n",
    "        )\n",
    "        proposal_offsets[1:] = num_points_per_proposal.cumsum(0) # cumsum 生成sum数组, 第一个留0, 成offset了\n",
    "\n",
    "        # voxelization\n",
    "        voxel_features, voxel_coords, pc_voxel_id = segmented_voxelize(\n",
    "            pt_xyz, pt_features,\n",
    "            proposal_offsets, proposal_indices,\n",
    "            num_points_per_proposal,\n",
    "            self.score_fullscale, self.score_scale,\n",
    "        )\n",
    "        voxel_tensor = spconv.SparseConvTensor(\n",
    "            voxel_features, voxel_coords.int(),\n",
    "            spatial_shape=[self.score_fullscale] * 3,\n",
    "            batch_size=num_proposals,\n",
    "        )\n",
    "        if not (pc_voxel_id >= 0).all():\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "            \n",
    "\n",
    "\n",
    "        proposals = Instances( # 包含了几乎所有信息\n",
    "            valid_mask=valid_mask,\n",
    "            sorted_indices=sorted_indices,\n",
    "            pt_xyz=pt_xyz,\n",
    "            batch_indices=batch_indices,\n",
    "            proposal_offsets=proposal_offsets,\n",
    "            proposal_indices=proposal_indices,\n",
    "            num_points_per_proposal=num_points_per_proposal,\n",
    "            sem_preds=sem_preds,\n",
    "            instance_labels=instance_labels,\n",
    "        )\n",
    "\n",
    "        return voxel_tensor, pc_voxel_id, proposals\n",
    "    def forward_proposal_score(\n",
    "        self,\n",
    "        voxel_tensor: spconv.SparseConvTensor,\n",
    "        pc_voxel_id: torch.Tensor,\n",
    "        proposals: Instances,\n",
    "    ):\n",
    "        proposal_offsets = proposals.proposal_offsets\n",
    "        proposal_offsets_begin = proposal_offsets[:-1] # type: ignore\n",
    "        proposal_offsets_end = proposal_offsets[1:] # type: ignore\n",
    "\n",
    "        score_features = self.score_unet(voxel_tensor)\n",
    "        score_features = score_features.features[pc_voxel_id]\n",
    "        pooled_score_features, _ = segmented_maxpool(\n",
    "            score_features, proposal_offsets_begin, proposal_offsets_end\n",
    "        )\n",
    "        score_logits = self.score_head(pooled_score_features)\n",
    "\n",
    "        return score_logits\n",
    "    def forward_proposal_npcs(\n",
    "        self,\n",
    "        voxel_tensor: spconv.SparseConvTensor,\n",
    "        pc_voxel_id: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        npcs_features = self.npcs_unet(voxel_tensor)\n",
    "        npcs_logits = self.npcs_head(npcs_features.features)\n",
    "        npcs_logits = npcs_logits[pc_voxel_id] # 通过pc_voxel_id转回成tensor的所有点\n",
    "\n",
    "        return npcs_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MainModel(\n",
      "  (backbone): SparseUNet(\n",
      "    (stem): SparseSequential(\n",
      "      (0): SubMConv3d(6, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "      (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (ublock): UBlock(\n",
      "      (encoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): SparseSequential(\n",
      "        (0): SparseConv3d(16, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (ublock): UBlock(\n",
      "        (encoder_blocks): SparseSequential(\n",
      "          (0): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (downsample): SparseSequential(\n",
      "          (0): SparseConv3d(32, 48, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (ublock): UBlock(\n",
      "          (encoder_blocks): SparseSequential(\n",
      "            (0): ResBlock(\n",
      "              (shortcut): Identity()\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (shortcut): Identity()\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (downsample): SparseSequential(\n",
      "            (0): SparseConv3d(48, 64, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (ublock): UBlock(\n",
      "            (encoder_blocks): SparseSequential(\n",
      "              (0): ResBlock(\n",
      "                (shortcut): Identity()\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResBlock(\n",
      "                (shortcut): Identity()\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (downsample): SparseSequential(\n",
      "              (0): SparseConv3d(64, 80, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (ublock): UBlock(\n",
      "              (encoder_blocks): SparseSequential(\n",
      "                (0): ResBlock(\n",
      "                  (shortcut): Identity()\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): ResBlock(\n",
      "                  (shortcut): Identity()\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (downsample): SparseSequential(\n",
      "                (0): SparseConv3d(80, 96, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU()\n",
      "              )\n",
      "              (ublock): UBlock(\n",
      "                (encoder_blocks): SparseSequential(\n",
      "                  (0): ResBlock(\n",
      "                    (shortcut): Identity()\n",
      "                    (conv1): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv2): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): ResBlock(\n",
      "                    (shortcut): Identity()\n",
      "                    (conv1): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv2): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (downsample): SparseSequential(\n",
      "                  (0): SparseConv3d(96, 112, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (2): ReLU()\n",
      "                )\n",
      "                (ublock): UBlock(\n",
      "                  (encoder_blocks): SparseSequential(\n",
      "                    (0): ResBlock(\n",
      "                      (shortcut): Identity()\n",
      "                      (conv1): SparseSequential(\n",
      "                        (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                        (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                      (conv2): SparseSequential(\n",
      "                        (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                        (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                    )\n",
      "                    (1): ResBlock(\n",
      "                      (shortcut): Identity()\n",
      "                      (conv1): SparseSequential(\n",
      "                        (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                        (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                      (conv2): SparseSequential(\n",
      "                        (0): SubMConv3d(112, 112, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                        (1): BatchNorm1d(112, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (upsample): SparseSequential(\n",
      "                  (0): SparseInverseConv3d(112, 96, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (2): ReLU()\n",
      "                )\n",
      "                (decoder_blocks): SparseSequential(\n",
      "                  (0): ResBlock(\n",
      "                    (shortcut): SparseSequential(\n",
      "                      (0): SubMConv3d(192, 96, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv1): SparseSequential(\n",
      "                      (0): SubMConv3d(192, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv2): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): ResBlock(\n",
      "                    (shortcut): Identity()\n",
      "                    (conv1): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                    (conv2): SparseSequential(\n",
      "                      (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                      (1): BatchNorm1d(96, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "              (upsample): SparseSequential(\n",
      "                (0): SparseInverseConv3d(96, 80, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU()\n",
      "              )\n",
      "              (decoder_blocks): SparseSequential(\n",
      "                (0): ResBlock(\n",
      "                  (shortcut): SparseSequential(\n",
      "                    (0): SubMConv3d(160, 80, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(160, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (1): ResBlock(\n",
      "                  (shortcut): Identity()\n",
      "                  (conv1): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                  (conv2): SparseSequential(\n",
      "                    (0): SubMConv3d(80, 80, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                    (1): BatchNorm1d(80, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (upsample): SparseSequential(\n",
      "              (0): SparseInverseConv3d(80, 64, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): ReLU()\n",
      "            )\n",
      "            (decoder_blocks): SparseSequential(\n",
      "              (0): ResBlock(\n",
      "                (shortcut): SparseSequential(\n",
      "                  (0): SubMConv3d(128, 64, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(128, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResBlock(\n",
      "                (shortcut): Identity()\n",
      "                (conv1): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "                (conv2): SparseSequential(\n",
      "                  (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                  (1): BatchNorm1d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (upsample): SparseSequential(\n",
      "            (0): SparseInverseConv3d(64, 48, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (decoder_blocks): SparseSequential(\n",
      "            (0): ResBlock(\n",
      "              (shortcut): SparseSequential(\n",
      "                (0): SubMConv3d(96, 48, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(96, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (shortcut): Identity()\n",
      "              (conv1): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (conv2): SparseSequential(\n",
      "                (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "                (1): BatchNorm1d(48, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (upsample): SparseSequential(\n",
      "          (0): SparseInverseConv3d(48, 32, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "          (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "        (decoder_blocks): SparseSequential(\n",
      "          (0): ResBlock(\n",
      "            (shortcut): SparseSequential(\n",
      "              (0): SubMConv3d(64, 32, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(64, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): SparseSequential(\n",
      "        (0): SparseInverseConv3d(32, 16, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (decoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): SparseSequential(\n",
      "            (0): SubMConv3d(32, 16, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(32, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sem_seg_head): Linear(in_features=16, out_features=10, bias=True)\n",
      "  (offset_head): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=16, out_features=3, bias=True)\n",
      "  )\n",
      "  (score_unet): SparseUNet(\n",
      "    (stem): SparseSequential(\n",
      "      (0): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (ublock): UBlock(\n",
      "      (encoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): SparseSequential(\n",
      "        (0): SparseConv3d(16, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (ublock): UBlock(\n",
      "        (encoder_blocks): SparseSequential(\n",
      "          (0): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): SparseSequential(\n",
      "        (0): SparseInverseConv3d(32, 16, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (decoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): SparseSequential(\n",
      "            (0): SubMConv3d(32, 16, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(32, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (score_head): Linear(in_features=16, out_features=9, bias=True)\n",
      "  (npcs_unet): SparseUNet(\n",
      "    (stem): SparseSequential(\n",
      "      (0): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (ublock): UBlock(\n",
      "      (encoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): SparseSequential(\n",
      "        (0): SparseConv3d(16, 32, kernel_size=[2, 2, 2], stride=[2, 2, 2], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (ublock): UBlock(\n",
      "        (encoder_blocks): SparseSequential(\n",
      "          (0): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): ResBlock(\n",
      "            (shortcut): Identity()\n",
      "            (conv1): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "            (conv2): SparseSequential(\n",
      "              (0): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "              (1): BatchNorm1d(32, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (upsample): SparseSequential(\n",
      "        (0): SparseInverseConv3d(32, 16, kernel_size=[2, 2, 2], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "        (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "      (decoder_blocks): SparseSequential(\n",
      "        (0): ResBlock(\n",
      "          (shortcut): SparseSequential(\n",
      "            (0): SubMConv3d(32, 16, kernel_size=[1, 1, 1], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(32, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResBlock(\n",
      "          (shortcut): Identity()\n",
      "          (conv1): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (conv2): SparseSequential(\n",
      "            (0): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm)\n",
      "            (1): BatchNorm1d(16, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (npcs_head): Linear(in_features=16, out_features=27, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc',\n",
       "  'random_pc'],\n",
       " Segmentation(batch_size=10, sem_preds=tensor([5, 4, 0,  ..., 5, 0, 7], device='cuda:0'), sem_labels=None, all_accu=None, pixel_accu=None),\n",
       " Instances(valid_mask=tensor([ True,  True, False,  ...,  True, False,  True], device='cuda:0'), sorted_indices=tensor([11525, 11877, 12005, 12027, 12522,    15,    93,   218,   509,   873,\n",
       "           378,   407,   934,  1000,  1281,  3418,  3590,  3694,  4143,  4343,\n",
       "          6830,  6976,  7056,  7124,  7612,  8650,  8692,  9280,  9456,  9499,\n",
       "          9804,  9806,  9869,  9901, 10477,  9932, 10228, 10312, 10554, 11216,\n",
       "         11827, 12025, 12357, 12470, 12585, 13163, 13761, 13994, 14370, 14528,\n",
       "         14581], device='cuda:0'), pt_xyz=tensor([[0.5938, 0.4266, 0.8013],\n",
       "         [0.6248, 0.4266, 0.8155],\n",
       "         [0.5656, 0.4180, 0.7876],\n",
       "         [0.6331, 0.3753, 0.7959],\n",
       "         [0.6415, 0.3992, 0.7975],\n",
       "         [0.4784, 0.1716, 0.3308],\n",
       "         [0.1729, 0.2443, 0.7373],\n",
       "         [0.4412, 0.1518, 0.6539],\n",
       "         [0.5422, 0.1322, 0.5717],\n",
       "         [0.4265, 0.1210, 0.6897],\n",
       "         [0.5878, 0.0819, 0.1537],\n",
       "         [0.6226, 0.1736, 0.1633],\n",
       "         [0.5483, 0.0796, 0.2827],\n",
       "         [0.3630, 0.2151, 0.2593],\n",
       "         [0.6019, 0.1187, 0.1073],\n",
       "         [0.9077, 0.4195, 0.1881],\n",
       "         [0.9135, 0.4554, 0.1068],\n",
       "         [0.8911, 0.4475, 0.1839],\n",
       "         [0.8231, 0.4098, 0.2619],\n",
       "         [0.8516, 0.3630, 0.3036],\n",
       "         [0.5796, 0.3972, 0.3567],\n",
       "         [0.4134, 0.4323, 0.2125],\n",
       "         [0.4826, 0.3676, 0.3973],\n",
       "         [0.3906, 0.4177, 0.2565],\n",
       "         [0.3496, 0.4391, 0.4332],\n",
       "         [0.6519, 0.3536, 0.4431],\n",
       "         [0.9313, 0.4304, 0.2139],\n",
       "         [0.7902, 0.5272, 0.1958],\n",
       "         [0.8664, 0.4452, 0.3850],\n",
       "         [0.7456, 0.5520, 0.1677],\n",
       "         [0.5929, 0.1737, 0.1140],\n",
       "         [0.5549, 0.3379, 0.0059],\n",
       "         [0.6381, 0.1124, 0.0993],\n",
       "         [0.6942, 0.2262, 0.0811],\n",
       "         [0.7605, 0.1069, 0.0152],\n",
       "         [0.6701, 0.6707, 0.1828],\n",
       "         [0.6244, 0.8454, 0.0323],\n",
       "         [0.6087, 0.6968, 0.0533],\n",
       "         [0.6194, 0.6448, 0.2155],\n",
       "         [0.6529, 0.7332, 0.0223],\n",
       "         [0.8468, 0.7610, 0.0751],\n",
       "         [0.9622, 0.5097, 0.2395],\n",
       "         [0.9298, 0.7000, 0.2551],\n",
       "         [0.9460, 0.8168, 0.1793],\n",
       "         [0.8600, 0.6564, 0.1251],\n",
       "         [0.5069, 0.0140, 0.1377],\n",
       "         [0.3210, 0.1566, 0.2307],\n",
       "         [0.2887, 0.1132, 0.2637],\n",
       "         [0.2304, 0.0622, 0.0529],\n",
       "         [0.5419, 0.0594, 0.1317],\n",
       "         [0.5458, 0.0754, 0.2415]], device='cuda:0'), batch_indices=tensor([7, 7, 7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 4, 4, 4, 4,\n",
       "         4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8,\n",
       "         8, 8, 8], device='cuda:0', dtype=torch.int32), proposal_offsets=tensor([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 51], device='cuda:0',\n",
       "        dtype=torch.int32), proposal_indices=tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "         4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9,\n",
       "         9, 9, 9], device='cuda:0'), num_points_per_proposal=tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 6], device='cuda:0'), sem_preds=tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5], device='cuda:0', dtype=torch.int32), pt_sem_classes=None, score_preds=tensor([0.5784, 0.2249, 0.3440, 0.2779, 0.3342, 0.3471, 0.3961, 0.3963, 0.3364,\n",
       "         0.6138], device='cuda:0'), npcs_preds=None, sem_labels=None, instance_labels=None, instance_sem_labels=None, num_points_per_instance=None, gt_npcs=None, npcs_valid_mask=None, ious=None, cls_preds=None, cls_labels=None, name=None))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_cfg = {\n",
    "    \"channels\": [16,32,48,64,80,96,112],\n",
    "    \"block_repeat\": 2\n",
    "}\n",
    "instance_seg_cfg = {\n",
    "      \"ball_query_radius\": 0.04,\n",
    "      \"max_num_points_per_query\": 50,\n",
    "      \"min_num_points_per_proposal\": 5, # 50 for scannet?\n",
    "      \"max_num_points_per_query_shift\": 300,\n",
    "      \"score_fullscale\": 28,\n",
    "      \"score_scale\": 50,\n",
    "}\n",
    "model = MainModel(in_channels=6,\n",
    "                  num_part_classes=10,\n",
    "                  backbone_type=\"SparseUNet\",\n",
    "                  backbone_cfg=backbone_cfg,\n",
    "                  instance_seg_cfg=instance_seg_cfg,\n",
    "                  debug=True,\n",
    "                  learning_rate=0.001,\n",
    "                  ignore_sem_label=-100,\n",
    "                  use_sem_focal_loss=True,\n",
    "                  use_sem_dice_loss=True,\n",
    "                  training_schedule=[5,10],\n",
    "                  val_nms_iou_threshold=0.3,\n",
    "                  val_ap_iou_threshold=0.5,\n",
    "                  symmetry_indices=[0, 1, 3, 3, 2, 0, 3, 2, 4, 1],).cuda()\n",
    "\n",
    "print(model)\n",
    "# 实例化一个PointCloud对象\n",
    "point_clouds = []\n",
    "for i in range(10):\n",
    "    pc = PointCloud(\n",
    "        pc_id=\"random_pc\",\n",
    "        points=np.random.rand(2000, 6).astype(np.float32),\n",
    "        obj_cat=[0, 2, 6],\n",
    "        sem_labels=None,\n",
    "        instance_labels=None\n",
    "    ).to_tensor()\n",
    "    pc = apply_voxelization(pc, voxel_size=[0.01,0.01,0.01])\n",
    "    point_clouds.append(pc.to(\"cuda\"))\n",
    "\n",
    "model(point_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False],\n",
      "        [False, False,  True,  True],\n",
      "        [ True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
      "cpu\n",
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "s = torch.tensor(range(16)).view(4,4)\n",
    "mask = s > 5\n",
    "print(mask)\n",
    "print(s[mask])\n",
    "s.to(\"cuda\")\n",
    "print(s.device)\n",
    "model_ttt = nn.Conv2d(3,3,3)\n",
    "print(next(model_ttt.parameters()).device)\n",
    "model_ttt.to(\"cuda\")\n",
    "print(next(model_ttt.parameters()).device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
